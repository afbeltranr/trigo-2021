z`?glm`
`?glm`
?glm
library(lmvar)
?lmvar::cv.lm
predictions8Var <- predict(mols,  newdata = as.data.frame(leavesSiSpectra[,gen$bestsets[3,]]))
predX8Var <- SiTable$Si
predY8var <- predictions8Var
table8bar <- data.frame(I( predX8Var),I(predY8var))
lm.C <- lm(predX8Var~predY8var)
plot(predX8Var,
predY8var,
xlab="Si real (ppm)" ,
ylab="Si predicho (ppm)",
pch=17,
cex=1.2,
col="darkorchid4",
cex.lab=1
)
abline(a=-5.856e-10  , b=1, col=1, lty=1, lwd=2)
# legend("topleft", recta.restado, pch=pch ,col=colfin, cex=1)
mols <- lm(metadata.leaves.Si$Si ~ leavesSiSpectra[,gen$bestsets[3,]], y = T, x = T)
summary(mols)
cv.lm(mols,
k=23)
dimnames(mols)
dimnames(mols)[2]
str(mols)
View(mols)
?lmvar
library(DAAG)
SiTablegen <- data.frame(cbind(metadata.leaves.Si$Si,
leavesSiSpectra[,gen$bestsets[3,]]))
colnames(SiTablegen)[1] <- 'Si'
SiCVgenmols <-  cv.lm(data = SiTablegen,
form.lm = formula(Si~.),
m = 23,
seed = 1)
library(DAAG)
SiTablegen <- data.frame(cbind(metadata.leaves.Si$Si,
leavesSiSpectra[,gen$bestsets[12,]]))
colnames(SiTablegen)[1] <- 'Si'
SiCVgenmols <-  cv.lm(data = SiTablegen,
form.lm = formula(Si~.),
m = 23,
seed = 1)
library(caret)
install.packages(caret)
install.packages('caret')
libary(tidyverse)
install.packages('tidyberse')
install.packages('tidyverse')
install.packages("tidyverse")
install.packages("tidyverse")
libary(tidyverse)
library(caret)
library(tidyverse)
?createDataPartition
View(gen$bestsets)
View(gen$bestsets[1,])
dim(gen$bestsets[1,])
nrow(gen$bestsets[1,])
nrow(gen$bestsets)
dim(gen$bestsets)
View(SiTable)
View(SiTablegen)
listOfTalbles <- vector('list', nrow(gen$bestsets))
listOfTables <- vector('list', nrow(gen$bestsets))
for(i in 1:nrow(gen$bestsets)){
listOfTables <-
}
for(i in 1:nrow(gen$bestsets)){
listOfTables[[i]] <- cbind(metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]]))
}
listOfTables[[1]]
listOfTables[[1]]2
listOfTables[[2]]
listOfTables <- vector('list', nrow(gen$bestsets))
listOfModels <- vector('list', nrow(gen$bestsets))
listOfModels <- vector('list', nrow(gen$bestsets))
for(i in 1:nrow(gen$bestsets)){
listOfTables[[i]] <- cbind(metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]]))
# setting seed to generate a
# reproducible random sampling
set.seed(125)
# defining training control as
# repeated cross-validation and
# value of K is 10 and repetation is 3 times
train_control <- trainControl(method = "repeatedcv",
number = 10, repeats = i)
# training the model by assigning sales column
# as target variable and rest other column
# as independent variable
listOfModels[[i]] <- train(Si ~.,
data = listOfTables[[i]],
method = "lm",
trControl = train_control)
}
listOfTables[[i]]
for(i in 1:nrow(gen$bestsets)){
listOfTables[[i]] <- cbind(si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]]))
# setting seed to generate a
# reproducible random sampling
set.seed(125)
# defining training control as
# repeated cross-validation and
# value of K is 10 and repetation is 3 times
train_control <- trainControl(method = "repeatedcv",
number = 10, repeats = i)
# training the model by assigning sales column
# as target variable and rest other column
# as independent variable
listOfModels[[i]] <- train(Si ~.,
data = listOfTables[[i]],
method = "lm",
trControl = train_control)
}
cbind(Si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[1,]]))
for(i in 1:nrow(gen$bestsets)){
listOfTables[[i]] <- cbind(Si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]]))
# setting seed to generate a
# reproducible random sampling
set.seed(125)
# defining training control as
# repeated cross-validation and
# value of K is 10 and repetation is 3 times
train_control <- trainControl(method = "repeatedcv",
number = 10, repeats = i)
# training the model by assigning sales column
# as target variable and rest other column
# as independent variable
listOfModels[[i]] <- train(Si ~.,
data = listOfTables[[i]],
method = "lm",
trControl = train_control)
}
for(i in 1:nrow(gen$bestsets)){
listOfTables[[i]] <- cbind(Si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]]))
# setting seed to generate a
# reproducible random sampling
set.seed(125)
# defining training control as
# repeated cross-validation and
# value of K is 10 and repetation is 3 times
train_control <- trainControl(method = "repeatedcv",
number = 10, repeats = 100)
# training the model by assigning sales column
# as target variable and rest other column
# as independent variable
listOfModels[[i]] <- train(Si ~.,
data = listOfTables[[i]],
method = "lm",
trControl = train_control)
}
View(train_control)
library(subselect)
Hmat <- lmHmat(leavesSiSpectra,metadata.leaves.Si$Si)
gen <- genetic(Hmat$mat, kmin =4, kmax = 12, H= Hmat$H, r =1, crit = 'CCR12', force = T)
Si ~.
listOfRMSEP <-
for(i in 1:nrow(gen$bestsets)){
listOfTables[[i]] <- cbind(Si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]]))
# setting seed to generate a
# reproducible random sampling
set.seed(125)
# defining training control as
# repeated cross-validation and
# value of K is 10 and repetation is 3 times
train_control <- trainControl(method = "repeatedcv",
number = 10, repeats = 1)
# training the model by assigning sales column
# as target variable and rest other column
# as independent variable
listOfModels[[i]] <- train(Si ~.,
data = listOfTables[[i]],
method = "lm",
trControl = train_control)
}
library(tidyverse)
library(caret)
# First we create a list of tables with the best subsets selected by the genetic algorithm
listOfTables <- vector('list', nrow(gen$bestsets))
listOfModels <- vector('list', nrow(gen$bestsets))
listOfRMSEP <-
for(i in 1:nrow(gen$bestsets)){
listOfTables[[i]] <- cbind(Si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]]))
# setting seed to generate a
# reproducible random sampling
set.seed(125)
# defining training control as
# repeated cross-validation and
# value of K is 10 and repetation is 3 times
train_control <- trainControl(method = "repeatedcv",
number = 10, repeats = 1)
# training the model by assigning sales column
# as target variable and rest other column
# as independent variable
listOfModels[[i]] <- train(Si ~.,
data = listOfTables[[i]],
method = "lm",
trControl = train_control)
}
# R program to implement
# repeated K-fold cross-validation
# setting seed to generate a
# reproducible random sampling
set.seed(125)
# defining training control as
# repeated cross-validation and
# value of K is 10 and repetation is 3 times
train_control <- trainControl(method = "repeatedcv",
number = 10, repeats = 3)
# training the model by assigning sales column
# as target variable and rest other column
# as independent variable
model <- train(Si ~., data = marketing,
method = "lm",
trControl = train_control)
library(tidyverse)
library(caret)
# First we create a list of tables with the best subsets selected by the genetic algorithm
listOfTables <- vector('list', nrow(gen$bestsets))
listOfModels <- vector('list', nrow(gen$bestsets))
listOfRMSEP <-
for(i in 1:nrow(gen$bestsets)){
listOfTables[[i]] <- cbind(Si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]]))
# setting seed to generate a
# reproducible random sampling
set.seed(125)
# defining training control as
# repeated cross-validation and
# value of K is 10 and repetation is 3 times
train_control <- trainControl(method = "repeatedcv",
number = 10, repeats = 1)
# training the model by assigning sales column
# as target variable and rest other column
# as independent variable
listOfModels[[i]] <- train(Si ~.,
data = listOfTables[[i]],
method = "lm",
trControl = train_control)
}
View(listOfModels)
# # R program to implement
# # repeated K-fold cross-validation
#
# # setting seed to generate a
# # reproducible random sampling
# set.seed(125)
#
# # defining training control as
# # repeated cross-validation and
# # value of K is 10 and repetation is 3 times
# train_control <- trainControl(method = "repeatedcv",
#                             number = 10, repeats = 3)
#
# # training the model by assigning sales column
# # as target variable and rest other column
# # as independent variable
# model <- train(Si ~., data = marketing,
#                method = "lm",
#                trControl = train_control)
#
# # printing model performance metrics
# # along with other details
# print(model)
print(listOfModels[[1]])
print(listOfModels[[]])
print(listOfModels[[2]])
print(listOfModels[[]])
print(listOfModels[[3]])
print(listOfModels[[4]])
library(tidyverse)
library(caret)
# First we create a list of tables with the best subsets selected by the genetic algorithm
listOfTables <- vector('list', nrow(gen$bestsets))
listOfModels <- vector('list', nrow(gen$bestsets))
listOfRMSEP <-
for(i in 1:nrow(gen$bestsets)){
listOfTables[[i]] <- cbind(Si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]]))
# setting seed to generate a
# reproducible random sampling
set.seed(125)
# defining training control as
# repeated cross-validation and
# value of K is 10 and repetation is 3 times
train_control <- trainControl(method = "repeatedcv",
number = 10, repeats = 100)
# training the model by assigning sales column
# as target variable and rest other column
# as independent variable
listOfModels[[i]] <- train(Si ~.,
data = listOfTables[[i]],
method = "lm",
trControl = train_control)
}
}
library(tidyverse)
library(caret)
# First we create a list of tables with the best subsets selected by the genetic algorithm
listOfTables <- vector('list', nrow(gen$bestsets))
listOfModels <- vector('list', nrow(gen$bestsets))
listOfRMSEP <-
for(i in 1:nrow(gen$bestsets)){
listOfTables[[i]] <- cbind(Si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]]))
# setting seed to generate a
# reproducible random sampling
set.seed(125)
# defining training control as
# repeated cross-validation and
# value of K is 10 and repetation is 3 times
train_control <- trainControl(method = "repeatedcv",
number = 10, repeats = 100)
# training the model by assigning sales column
# as target variable and rest other column
# as independent variable
listOfModels[[i]] <- train(Si ~.,
data = listOfTables[[i]],
method = "lm",
trControl = train_control)
}
# # R program to implement
# # repeated K-fold cross-validation
#
# # setting seed to generate a
# # reproducible random sampling
# set.seed(125)
#
# # defining training control as
# # repeated cross-validation and
# # value of K is 10 and repetation is 3 times
# train_control <- trainControl(method = "repeatedcv",
#                             number = 10, repeats = 3)
#
# # training the model by assigning sales column
# # as target variable and rest other column
# # as independent variable
# model <- train(Si ~., data = marketing,
#                method = "lm",
#                trControl = train_control)
#
# # printing model performance metrics
# # along with other details
# print(model)
print(listOfModels[[1]]$finalModel)
print(listOfModels[[1]])
summary(listOfModels[[1]])
print(model)
?trainControl
?train
listOfRMSEP <- vector('list', nrow(gen$bestsets))
View(listOfModels)
listOfModels[[1]]$results
listOfModels[[1]]$resample
head(listOfModels[[1]]$resample$RMSE)
boxplot(listOfModels[[1]]$resample$RMSE)
boxplot(listOfModels[[2]]$resample$RMSE)
boxplot(listOfModels[[3]]$resample$RMSE)
boxplot(listOfModels[[4]]$resample$RMSE)
boxplot(listOfModels[[5]]$resample$RMSE)
par(mfrow(1,5))
par(mfrow = c(1,5))
boxplot(listOfModels[[5]]$resample$RMSE)
boxplot(listOfModels[[4]]$resample$RMSE)
length(listOfModels[[2]]$resample$RMSE)
length(listOfModels[[1]]$resample$RMSE)
length(listOfModels[[2]]$resample$RMSE)
library(tidyverse)
library(caret)
# First we create a list of tables with the best subsets selected by the genetic algorithm
listOfTables <- vector('list', nrow(gen$bestsets))
listOfModels <- vector('list', nrow(gen$bestsets))
listOfRMSEP <- vector('list', nrow(gen$bestsets))
system.time(
for(i in 1:nrow(gen$bestsets)){
listOfTables[[i]] <- cbind(Si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]]))
# setting seed to generate a
# reproducible random sampling
set.seed(125)
# defining training control as
# repeated cross-validation and
# value of K is 10 and repetation is 3 times
train_control <- trainControl(method = "repeatedcv",
number = 10, repeats = 100)
# training the model by assigning sales column
# as target variable and rest other column
# as independent variable
listOfModels[[i]] <- train(Si ~.,
data = listOfTables[[i]],
method = "lm",
trControl = train_control)
listOfRMSEP[[i]] <- listOfModels[[i]]$resample$RMSE
}
)
# # R program to implement
# # repeated K-fold cross-validation
#
# # setting seed to generate a
# # reproducible random sampling
# set.seed(125)
#
# # defining training control as
# # repeated cross-validation and
# # value of K is 10 and repetation is 3 times
# train_control <- trainControl(method = "repeatedcv",
#                             number = 10, repeats = 3)
#
# # training the model by assigning sales column
# # as target variable and rest other column
# # as independent variable
# model <- train(Si ~., data = marketing,
#                method = "lm",
#                trControl = train_control)
#
# # printing model performance metrics
# # along with other details
# print(model)
length(listOfRMSEP[[1]])
class(listOfRMSEP[[1]])
RMSEP <- c(listOfRMSEP[[1]],listOfRMSEP[[2]],listOfRMSEP[[3]],listOfRMSEP[[4]],listOfRMSEP[[5]],listOfRMSEP[[6]],listOfRMSEP[[7]],listOfRMSEP[[8]],listOfRMSEP[[9]])
View(gen)
RMSEPTable <- data.frame(RMSEP = RMSEP, variables = c(rep(4,1000),rep(5,1000),rep(6,1000),rep(7,1000),rep(8,1000),rep(9,1000),rep(10,1000),rep(11,1000),rep(12,1000)))
library(ggplot2)
ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE, fill="gray")+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")+
geom_boxplot(width=0.1)+
theme_classic()
RMSEPTable$variables <- as.factor(RMSEPTable$variables)
library(ggplot2)
ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE, fill="gray")+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")+
geom_boxplot(width=0.1)+
theme_classic()
library(ggplot2)
p<- ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE, fill="gray")+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")+
geom_boxplot(width=0.1)+
theme_classic()
p
win.graph()
p<- ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE, fill="gray")+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")+
geom_boxplot(width=0.1)+
theme_classic()
p
p<- ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE, fill="gray")+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")+
geom_boxplot(width=0.1)+
theme_classic()
p
p<- ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE, fill="gray")+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")+
geom_boxplot(width=0.1)+
scale_fill_brewer(palette="Blues") + theme_classic()
p
p<- ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE)+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")+
geom_boxplot(width=0.1)+
scale_fill_brewer(palette="Blues") + theme_classic()
p
dp <- ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE)+
geom_boxplot(width=0.1, fill="white")+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")
dp + scale_fill_brewer(palette="Dark2") + theme_minimal()
dp <- ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE)+
geom_boxplot(width=0.1, fill="white")+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")
dp + scale_fill_brewer(palette="Blues") + theme_classic()
win.graph
win.graph()
dp + scale_fill_brewer(palette="Blues") + theme_classic()
win.graph()
dp + scale_fill_brewer(palette="Blues") + theme_classic()
dp <- ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE)+
geom_boxplot(width=0.1, fill=variables)+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")
dp <- ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE)+
geom_boxplot(width=0.1, fill=RMSEPTable$variables)+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")
dp + scale_fill_brewer(palette="Blues") + theme_classic()
dp <- ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE)+
geom_boxplot(width=0.1, fill='slateblue')+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")
dp + scale_fill_brewer(palette="Blues") + theme_classic()
dp <- ggplot(RMSEPTable, aes(x=variables, y=RMSEP)) +
geom_violin(trim=FALSE)+
geom_boxplot(width=0.1, fill='white')+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")
dp + scale_fill_brewer(palette="Blues") + theme_classic()
dp <- ggplot(RMSEPTable, aes(x=variables, y=RMSEP, fill=variables)) +
geom_violin(trim=FALSE)+
geom_boxplot(width=0.1, fill='white')+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")
dp + scale_fill_brewer(palette="Blues") + theme_classic()
win.graph()
dp <- ggplot(RMSEPTable, aes(x=variables, y=RMSEP, fill=variables)) +
geom_violin(trim=FALSE)+
geom_boxplot(width=0.1, fill='white')+
labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)")
dp + scale_fill_brewer(palette="Blues") + theme_minimal()
