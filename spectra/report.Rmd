---
title: "The structure and interaction of silica in plant cell walls: Data analysis report"
author: "Felipe Beltran"
date: "6/16/2021"
output:
    pdf_document
fig_caption: yes
classoption:
- twocolumn
---
```{r defining graphical functions, echo = F}
rgl_init <- function(new.device = FALSE, bg = "white", width = 640) { 
  if( new.device | rgl.cur() == 0 ) {
    rgl.open()
    par3d(windowRect = 50 + c( 0, 0, width, width ) )
    rgl.bg(color = bg )
  }
  rgl.clear(type = c("shapes", "bboxdeco"))
  rgl.viewpoint(theta = 15, phi = 20, zoom = 0.7)
}
rgl_add_axes <- function(x, y, z, axis.col = "black",#91.72  7.59  0.63 => 99.94
                xlab = "PC1 - 91.72 %", ylab="PC2 -7.59 %", zlab="PC3 - 0.63 %", show.plane = FALSE, 
                show.bbox = TRUE, bbox.col = c("white","black"))
  { 
  
  lim <- function(x){c(-max(abs(x)), max(abs(x))) * 1.1}
  # Add axes
  xlim <- lim(x); ylim <- lim(y); zlim <- lim(z)
  rgl.lines(xlim, c(0, 0), c(0, 0), color = axis.col)
  rgl.lines(c(0, 0), ylim, c(0, 0), color = axis.col)
  rgl.lines(c(0, 0), c(0, 0), zlim, color = axis.col)
  
   # Add a point at the end of each axes to specify the direction
   axes <- rbind(c(xlim[2], 0, 0), c(0, ylim[2], 0), 
                 c(0, 0, zlim[2]))
   rgl.points(axes, color = axis.col, size = 3)
  
  # Add axis labels
  rgl.texts(axes, text = c(xlab, ylab, zlab), color = axis.col,
             adj = c(0.5, -0.8), size = 2)
  
  # # Add plane
  # if(show.plane) 
  #   xlim <- xlim/1.1; zlim <- zlim /1.1
  #   rgl.quads( x = rep(xlim, each = 2), y = c(0, 0, 0, 0),
  #            z = c(zlim[1], zlim[2], zlim[2], zlim[1]))
  
  # Add bounding box decoration
  if(show.bbox){
    rgl.bbox(color=c(bbox.col[1],bbox.col[2]), alpha = 0.5, 
          emission=bbox.col[1], specular=bbox.col[1], shininess=5, 
          xlen = 3, ylen = 3, zlen = 3) 
  }
}

```


# Introduction

In this document we will save all data manipulation and analysis related to the infrared spectra from the project: **The structure and interaction of silica in plant cell walls**


# Loading data into `R`

First, we create an object called `names`, which is a `list`, in which we will save the names of the files with the `.CSV` extension contained in [this](https://github.com/pipoelpipas/trigo-2021/tree/main/spectra) folder.

```{r creating names list}
names <- list.files(pattern = '.CSV')
```

Then, we use the function `lapply` to apply the function `read.csv` to each element of the list `names` and then save each of the `data.frames` from the files in to R.
```{r reading each data frame}
spectra.list <- lapply(names, 
                       read.csv, 
                       header = F)
```

Now, se can save the frequencies of incident light as a vector called `wavenumbers`. The code `spectra.list[[1]][1]` selects the first element of the list `spectra.list` using the index operator for lists `[[1]]`, which is a `data.frame`. Then, we select the first column of that `data.frame` using the index operator `[1]`:


```{r extracting wave numbers}
wavenumbers <- unlist(spectra.list[[1]][1])
```

The object `wavenumbers` has 1 row and 1869 columns, each column is one of the frequencies used by the spectrometer in the experiment.

As we did previously, we can use again the function `lapply` to apply the index operator `[` and select ONLY the second column of each `data.frame` that has inside the absorbance at each frequency.

```{r extracting just absorbances}
spectra.list2 <- lapply(spectra.list, '[', 2)
```

In order to make data easier to manipulate, we can transform the list of columns called `spectra.list2` into a `data.frame` as follows:

```{r converting list of df to one df}
spectra.df <- as.data.frame(
  t(as.data.frame(spectra.list2))
  )
```

the object `spectra.df` has 318 rows, i.e. 318 spectra from different samples and 1869 columns, or infrared frequencies.

Since the function `t()` transforms `data.frame` class objects into `matrix` class objects, we have to assign again to `spectra.df` (a matrix) the corresponding column and row names:

```{r assigning names 1}
rownames(spectra.df) <- names
colnames(spectra.df) <- wavenumbers
# gsub('.{6}$', '', names)
```

## Tidying up the `data.frame`


Since the names of the sample right now have the following structure:

```{r checking names}
head(names[1:3])
```


We can get rid of the unnecessary characters in the names of the samples, such as the extension and other symbols such as `"` or `.`. For that we can use the function `gsub()` and `regex` or regular expressions in order to replace these symbols for nothing, or `''`.

The regular expression for this replacement is built as follows:

* `.` matches any element that complies with the requirement, or applies the query to every element
* `{4}` replaces characters by `''` exactly 4 times
* `$` matches the end of each name

That is described before allows us to tell `R` that we want to replace the last 4 characters in each name by nothing, or `''`.

```{r correcting names length}
names2 <- gsub('.{4}$', 
               '', 
               rownames(spectra.df))
head(names2[1:4])
```
There are some samples that have longer names, such as:

```{r checking names 2}
head(names2[292:318])
```
We can also save just the information that is useful for displaying in tables and plots:

```{r correcting names length 2}
names2[292:318] <- gsub('.{41}$', 
                        '',
                        rownames(
                          spectra.df
                          )[292:318])
head(names2[292:318])[1:4]
```
Finally, we assign the curated names to our data frame, `spectra.df`

```{r assigning corrected names}
rownames(spectra.df) <- names2
```


# Plotting intial data

Since we have joined several spectra from different samples, we can try to visualize what we are dealing with. 

Knowing that we have already the names of the samples, it would be handy if we used a factor that helped us to differentiate replicas of experiments:

```{r creating factor for coloring replicas, attr.source="style='display:inline-block;'", collapse=TRUE}
cols <- factor(gsub('.{2}$', '', names2))
str(cols)
```
If we use the factor `cols`, we can plot three replicas of one sample using the same color

Now, we can use a loop to plot each one of the rows of our `data.frame`: 

```{r raw data plot, fig.cap="\\label{fig:figs}raw spectra of triplicated samples"}

for(i in  1:length(rownames(spectra.df))){
  
  plot(wavenumbers,
    spectra.df[i,],
    axes = F,
    xlab = '', 
    ylab = '',
    xlim = c(4000, 400),
    ylim= c(0,0.2),
    type = 'l',
    col =cols[i]

  )
  par(new = T)
}

box()
axis(1)
axis(2)
title(main = '',
      xlab = expression(
        paste('Wave number (cm'^'-1',
              ')')
        ),
      ylab ='absorbance (a.u.)')
```

As we can see in Figure \ref{fig:figs} In the range between 2500 and 2000 cm-1 variability due to experimental noise and background correction is present. In order to use multivariate methods and extract the chemical information from the dataset, we can select a region of interest (ROI) in which we take into account characteristic bands for molecules which concentration can be different between samples, such as silicon oxides, or lignin monomers.

# range selection

Now, we can check for where is that ROI in our data frame. Since the frequencies are arranged along the columns, we can search for the columns that have column names between 1700 and 400 $cm^{-1}$

```{r revision of the column position for ROI }
colnames(spectra.df)[c(1,676)]
```
Once we know where the ROI is in the data frame, we can create a subset called `range1` to store the spectra of all samples within this range, and plot it:

```{r ROI selection}
range1 <- spectra.df[,c(1:676)]
wavenumbers1 <- wavenumbers[c(1:676)]
```

```{r ROI plot, fig.cap="\\label{fig:figs}ROI spectra of triplicated samples"}
for(i in  1:length(rownames(range1))){

  plot(wavenumbers1,
    range1[i,],
    axes = F,
    xlab = '',
    ylab = '',
    xlim = c(1700, 400),
    ylim= c(0,0.2),
    type = 'l',
    col =cols[i]

  )
  par(new = T)
}

box()
axis(1)
axis(2)
title(main = 'raw spectra - ROI',
      xlab = expression(
        paste('Wave number (cm'^'-1',
              ')'
              )),
      ylab ='absorbance (a.u.)')

```


# mean spectra calculation

Since each sample has three replicated spectra, we can calculate the mean of each three samples as follows:


* First, we create a vector to tell R which samples to look for. Using the function `unique()` we extract the unique values without taking their repetitions:

```{r search vector}
search.vector <- unique(unlist(cols))
head(search.vector)
```
Once we have the names for each sample, we can search for $\dfrac{318}{3}=106$ triads of samples. Once we know where they are, we can calculate the mean for each three replicates.

First, we create a list in which we are going to save the position of each three spectra:

```{r creating index list for means}
index <- list(106)
```


Now we can again use the help of regular expressions to search for every sample that matches with one single sample:

As an example:

The regular expression that we will use this time is `(?=.*<search>)` where `<search>` is replaced with the sample's name.

This will find any element for the vector `rownames(spectra.df)` that matches with the character in `search vector`. For example, if we search for the first sample, `search.vector[1]` which is sample `125`:

```{r first sample name}
as.character(search.vector[1]) # the name of 
#the first sample
```
The search will tell us the positions in `rownames(spectra.df)` where where we can find the character `'125'` 

```{r regex for means example}
 which(
   grepl(
     paste0('(?=.*',
            as.character(search.vector[1]),
            ')'
            ),
     rownames(spectra.df),
     perl=T
     ) 
   )
```
Then we can confirm:

```{r checking regex for means}
rownames(spectra.df)[c(1, 2, 3)]
```

This process can be automated using a `for` loop in R:

```{r seaching for means using regex}

for (i in 1:106){

  index[[i]] <- which(
    grepl(
      paste0('(?=.*',
             as.character(search.vector[i])
             ,')'),
                       rownames(spectra.df),
                       perl=T
                       )
                 )
}
```

```{r checking for results of regex search}
search.vector[2]
rownames(spectra.df)[c(index[[2]])]
```


Once we know where each triplicate is, we can proceed to calculate the means:

* First, we create a matrix to save the mean spectra that will result from the calculation. 

```{r creation of mean matrix}
mean <- matrix(ncol= ncol(range1),
               nrow = nrow(range1)/3)
```

*Then, we assign to this empty matrix, `mean`, its corresponding column and row names:

```{r asigning dimnames to mean}
# mean <- as.data.frame(mean)

colnames(mean) <- colnames(range1)
rownames(mean) <- search.vector
```


Then we can loop through columns indexing each wave number, one after another, in each iteration of the loop, or each time `j` changes its value. Posibles values for `j` are defined when `in 1:length(ncol(range1))`. where `ncol` gives us the number of columns of `range1` or the number of wave numbers present along the ROI.

At the same time, `i` takes values at each one of the numbers present between `1` and `nrow(mean)`

at step 1 in both loops, we save in the position `mean[1,1]` the resulting value when we use the function `mean()` which as default calculates the arithmetic mean (when the argument trim = 0 is given as default, the function trims a fraction of 0 observations from each end of the three observations before the means is computed.)

In order to calculate this mean estimator from a sample of 3 replicates, we index the spectral matrix `range1` in three special positions for each sample, those found in the creation of the  `index` list. 

In this step of the calculation, the first value of absorbance for the sample 125 at wave number 399.1, is empty, as are all the other slots of this matrix.

```{r checking initial state of mean}
mean[1,1]
```

for example, for the first sample, and the first wave number, we will save the result of the calculation of the mean of three replicas of sample 125, and at a wave number of 399.1, `mean[1,1]`.In order to accomplish this, we select the first position of the list `index[[1]]`:

```{r showing where the 3 replicas for 125 are}
index[[1]]

```

when we print the content of this position of the list, we can notice that the samples `125-1` `125-2` and `125-3` lie in the positions 1, 2, and 3 respectively of the data.frame `range1`.

So the calculation will be applied to `range1[index[[1]][1],1]`, `range1[index[[1]][2],1]` and `range1[index[[1]][2],1]`, or rows 1, 2, and 3. 

the process is then repeated through all of the wave numbers (columns) and samples (rows) of the data set.

```{r calculating the means}

for(j in 1:ncol(range1)){

for(i in 1:nrow(mean)){

mean[i,j] <- mean(c(range1[index[[i]][1],j],
                    range1[index[[i]][2],j],
                    range1[index[[i]][3],j]
                      ) )
}
}
```

then we turn this matrix into a data.frame: 

```{r making mean a data frame}
mean <- as.data.frame(mean)
```

Once we have calculated the mean for each sample, we can plot the resulting mean spectra using the same factor used before, `cols` to color each sample of the same color of their triplicates.

```{r plotting the mean, fig.cap="\\label{fig:figs}Calculated mean spectra"}

cols.means <- as.factor(search.vector)

for(i in  1:length(rownames(mean))){

  plot(wavenumbers1,
    mean[i,],
    axes = F,
    xlab = '',
    ylab = '',
    xlim = c(1700, 400),
    ylim= c(0,0.135309),
    type = 'l',
    col =cols.means[i]

  )
  par(new = T)
}

box()
axis(1)
axis(2)
title(main = '',
      xlab = expression(
        paste('Wave number (cm'^'-1',
              ')')
        ),
      ylab ='absorbance (a.u.)')
```


Once we have calculated the mean estimator for each multivariate spectra, we can proceed to perform pre-treatments in order to clean the data, and extract as much as chemical information as we can.

# baseline correction

In this experiment we have performed an analogue to the the baseline correction described by [beleites et al. 2020](https://cran.r-project.org/web/packages/hyperSpec/vignettes/baseline.pdf):

```{r loading hyperspec, message= FALSE}
library(hyperSpec) 
# hyperSpec package functions and 
#data is charged in this session
```

We create an object that can be identified and manipulated by the functions of `hyperSpec` package.

```{r saving spectra into hyperSpec object }
spc <- new('hyperSpec', # The class of the object
           spc= mean, # the spectra matrix
           wavelength = wavenumbers1
 # independent variable, whether wave number 
#or wave length          
           ) 


```

then in an object called `bend`,  we can save the result of `wl.eval` applied to `spc`. This function generates a baseline 'reference spectra':

```{r calculation of bend reference spectra}
bend <- 0.1 * wl.eval(spc,
                      function (x) 
                      x^6+x^5+x^4+x^3+x^2,
                      normalize.wl = 
                        normalize01)

```

*   `function (x) x^6+x^5+x^4+x^3+x^2` defines a polynomial that is used to fit the baselines to the supporting points in the lower region of the spectra contained in 'spc', using this functions the baseline 'reference spectra' is calculated 
     
* `normalize.wl=normalize01` is a function used to transform the wave numbers before evaluating the polynomial. using `normalize01` we map the range of each wave number to the interval $[0,1]$ 

* the multiplication by $0.1$ is the normalization chosen for these spectra.

Now we can use the `rubberband` method to estimate the baseline. Setting the noise to $1\cdot10^{-4}$ allows us to take advantage of the low noise presented for this spectra. (a noise of `noise=4` sets an interval of 2 times standard deviations).

```{r baseline calculation}
bl <- spc.rubberband(spc+bend,
                     noise = 1e-4, 
                     df = 20)-bend
```

The base-line correction method selected for this work is one of many, and tuning the correction parameters can be subject to a design of experiments, using as a response variable a quality measure of the analysis that is going to be performed after the correction. For example $Q^2$ for PCA, or $R_{adj}$ and $RMSEP_{CV}$ for multiple linear regression models as suggested by [hovde 2010](https://doi.org/10.1366/000370210792434350). 

Now, we can visualize the results of these baseline corrections.

First, the spectra before correction and the estimated baseline 'reference spectra':

```{r baseline plot 1, fig.cap="\\label{fig:figs}Mean spectra and rubberband baseline"}
labels (spc, ".wavelength") <-
  expression(paste(
    'Wave number (cm'^'-1',
    ')'))
labels (spc, "spc") <- 
  expression(paste('Absorbance (a.u.)'))

plot(spc, wl.reverse = TRUE)
plot(bl, add=TRUE, col=2,wl.reverse = TRUE)
``` 

And the heart of the rubberband method, the bending of the spectra to add support points in the convex part of the spectra:

```{r baseline plot 2 bend, fig.cap="\\label{fig:figs}bent mean spectra and bent baseline"}

sum <- spc+bend
plot(sum,wl.reverse = TRUE)
plot(bend, add=TRUE, col=2,wl.reverse = TRUE)
```

Then, the corrected spectra, which is calculated by substracting the baseline `bl` from the spectra `spc`:


```{r baseline plot 3 corrected, fig.cap="\\label{fig:figs}baseline corrected mean spectra"}
spc3 <- spc - bl
spc3 <- spc3 + (min(spc3)*-1)
# We add the minimum value
#which is negative to have only positive 
#values
plot(spc3,wl.reverse = TRUE)

```

Now, we can extract the corrected spectra from the `hyperSpec` object and save it as a `data.frame` to handle the information in an easier way later.
```{r saving the corrected spectra as a data frame}
corrected1  <- as.data.frame(spc3[1:106])
corrected <- as.data.frame(corrected1[,1])
corrected <- corrected + (min(corrected)*-1) # shifting upwards to prevent negative values
```

Up to this point, we have calculated the mean spectra and corrected the base-line of each spectrum. 


# multiplicative scatter correction (MSC)

Since This is a popular pre-treatment [(Rinnan 2009](https://www.sciencedirect.com/science/article/abs/pii/S0165993609001629), [Wu 2018)](https://www.sciencedirect.com/science/article/abs/pii/S0168169917309687) we tried to use it in this study.   


```{r MSC correction, message=FALSE}
library(pls)
correctedMSC <- msc(as.matrix(mean))
```

```{r MSC correction plot, fig.cap="\\label{fig:figs}MSC correction of mean spectra "}

for (i in 1:length(rownames(correctedMSC))){

  plot(as.numeric(colnames(correctedMSC)),
     correctedMSC[i,],
     xlab = '',
     ylab = '',
     axes = F,
     type = 'l',
     xlim = c(1700,400),
     ylim = c(0,0.12),
     col = cols[i])
  par(new = T)
}
box()
axis(1)
axis(2)
title(main = '',
      xlab = expression(paste(
        'Wave number (cm'^'-1',
        ')')),
      ylab = 'Absorbance (a.u.)')
```

Since no noise reduction was identified, this option was dismissed for the moment.

# metadata


First, we load the metadata table, created from the data table 'Datos_para_colombia.xlsx' available [here](https://github.com/pipoelpipas/trigo-2021/blob/main/Lignina/Datos%20para%20Colombia.xlsx):

```{r reading metadata table}
library(readxl)
metadata <- read_excel("metadata.xlsx")
```

The object called metadata is a data.frame and it has 88 rows and columns as it is. The rows vary with samples and the columns with variables. The variables in the columns are:

```{r printing the column names of metadata matrix, collapse=TRUE}
options(width = 30)
colnames(metadata)
```
where:

* `sample`: Contains the alpha numeric ID given to each sample. *class=numeric*.
* `class`:  The group of the experiment from where the sample comes from *class=character*.
* `N %`: The nitrogen percent quantified.  *class=numeric*.
* `C %`: The nitrogen percent quantified. *class=numeric*.
* `Si`: Silicon quantified by ICP-OES *class=numeric*.
* `Ca`: Calcium quantified by ICP-OES *class=character*.
* `Mg`: magnesium quantified by ICP-OES *class=character*.
* `P`: Phosphorous quantified by ICP-OES *class=character*.

Since the raw data is not debugged (as the majority of experimental raw data sometimes are) we can tidy up this table as far as we can using `R`.

First we can search if there is any row of the `metadata` that has its label or ID missing using the column `sample`:

```{r checking for NA in metadata}
which(is.na(metadata$sample))
```
The row 17 has an NA or blank space in the column `sample`. we can proceed to remove this row:


```{r }
metadata <- metadata[-c(17),]
which(is.na(metadata$sample))
```
`integer(0)` means that once we have deleted row 17, there are no blank spaces whatsoever.


## matching samples that have metadata with samples with spectra


We can now try to find where in the rows of `corrected` are the samples listed in `metadata$sample`. Doing this we will know which sample that has quantification and classification data, also has spectra available and where it is.

```{r}

positions <- vector('list', 87) # the same sizeas metadata$sample

for (i in 1:87){

positions[[i]] <- which(
                  grepl(
                  paste0('(?=.*',
                  as.character(
                    metadata$sample[i]),
                        ')'),
                  rownames(corrected), 
                 perl=T
                             )
                       )
}


```

In `positions`, an object of *class=list* we save in each position where in the data frame `corrected` the current sample is. For instance:

```{r}
metadata$sample[1] 
```


```{r}
positions[[1]]
```
```{r}
rownames(corrected)[positions[[1]]]
```
In the last chunk we print the name of the spectra, `rownames(corrected)`, that is selected by the indexing list `positions[[1]]` which is `125`, the same sample at the first row of `metadata`. 

This seems a little bit obvious but in the raw data there are several spectra rows that have not matching quantification data, or vice versa, there are several samples that have quantification information but have no spectra available.

Since now whe know where in the spectral matrix is each sample of the `metadata` data set, we can add a new column that relates where is each sample of `metadata` in the `corrected` matrix:

<!-- Now, we can create a new column in metadata, to state which sample has spectra: -->

```{r matching for metadata$sample and rownames$corrected selected by  positions[[i]]}
for(i in 1:length(metadata$sample)) {

  if(length(positions[[i]]) == 1){

    metadata$spectra[i] <- 
      rownames(corrected)[positions[[i]]]
  }else{
    metadata$spectra[i] <- NA
  }

}
```

Now we can compare if the indexing tool `positions` is doing its job. Creating the `data.frame` called `compare` we list side to side the names of `metadata` samples and the names of `corrected samples`

```{r comparing metadata$samples and rownames(corrected)}
compare <- data.frame(metadata = 
                        metadata$sample, 
                      spectra = 
                        metadata$spectra)
head(compare)
```


Since now we know where in `corrected` is each spectra for each sample from `metadata`, we can add this information to the `metadata` table:

```{r searching the index number for metadata samples in corrected}
for(i in 1:length(metadata$sample)) {

  if(length(positions[[i]]) == 1){

    metadata$spectra.index[i] <- positions[[i]]
  }else{
    metadata$spectra.index[i] <- NA
  }

}
```

This is an analogue process to that used for saving the names of the spectra contained in `corrected`. The difference is that now in the column `metadata$spectra.index` we have exactly where the sample of the current row, is in the rows of the `corrected` matrix.


# Exploratory Data analysis

# Hierarchical clustering

Hierarchical clustering can be used to measure multidimensional distances between objects, or samples. If the objective is to use this analysis we have to first tidy up the data and prepare it for the analysis.

First, we can search for missing values in the classification column:

```{r}
which(is.na(metadata$class))
```
Now, once is known that samples in rows 7 and 26 have no classification, we can create a new data table without these

```{r}


metadata.class <- metadata[-c( which(is.na(metadata$class))),]

which(is.na(metadata.class$class))

```

Once the samples that have no classification information have been removed, it is useful to check if there is any missing spectrum for the remaining samples:

```{r}
which(is.na(metadata.class$spectra.index))
```
Since these samples have no spectra, they can be also removed as follows:

```{r}
metadata.class2 <- metadata.class[-c(which(is.na(metadata.class$spectra.index)) ),]
which(is.na(metadata.class2$spectra.index))
```

The next thing needed for the analysis is the spectra.
It is important that each classification matches each spectra:


```{r}
spectra.class <- corrected[metadata.class2$spectra.index,]
```

Then we can compare if we have the same samples in both tables:

```{r}
compare.class <- data.frame(classification = metadata.class2$sample,
                            spectra= rownames(spectra.class))
head(compare.class)

```



```{r}

df1 <- spectra.class

names.class <- paste(metadata.class2$class, rownames(spectra.class))

rownames(df1) <- names.class
logdf <- log10(df1[,1:676] + 1)
rownames(logdf) <- names.class
library(factoextra)


hClust1 <- hclust(dist(logdf))
plot(hClust1)
res.hk <-hkmeans(logdf, 
                 5,
                 hc.metric =  'euclidean')

fviz_dend(res.hk, cex = 0.5, palette = "jco", 
          rect = TRUE, rect_border = "jco", rect_fill = TRUE)
```



```{r}
colspca <- vector('character', nrow(df1))



for(i in 1:nrow(df1)){
  if( grepl(
    paste0('(?=.*',
           'L',
           ')'),
    metadata.class2$class[i],perl = T)){colspca[i] <- 'black'}else{
      if(grepl(
    paste0('(?=.*',
           'R',
           ')'),
    metadata.class2$class[i],perl = T)){colspca[i] <- 'red'}else{colspca[i] <- 'white'}
    }
}

pcaall <- prcomp(spectra.class)

vp <- (pcaall$sdev)^2

variance <- round(vp/sum(vp)*100,2)

coord <- pcaall$x

plot(coord[,1],
     coord[,2], 
     col=colspca,
     xlab="PC1 - 40.74 %",
     ylab= "PC2 - 16.46 %",

     pch=19
     )
abline(v=0, h=0, lty=2)
 text(coord[,1],coord[,2], rownames(coord), cex=0.4, pos=1)
 
 
```

<!-- ```{r setup, echo=FALSE} -->
<!-- library(rgl) -->
<!-- knitr::knit_hooks$set(webgl = hook_webgl) -->
<!-- ``` -->

<!-- ```{r , webgl=TRUE, results='hide'} -->
<!-- library(rgl) -->
<!-- x <- coord[,1] -->
<!-- y <- coord[,2] -->
<!-- z <- coord[,3] -->
<!-- rgl_init()          -->
<!-- r3dDefaults$windowRect <- c(0,50, 1200, 1200)  -->
<!-- rgl.spheres(x, y, z, r = 0.002, color = colspca)  -->
<!-- # text3d(x,y,z, rownames(coord), pos=3, col="black") -->
<!-- rgl_add_axes(x, y, z, show.bbox = FALSE) -->
<!-- aspect3d(1,1,1) -->

<!-- ``` -->



# Leaves selection
## Selection of samples

prior work (PCA applied to the same spectra, with different pre-treatment) indicates that leave samples presented more variability. thus, it is worth it to subset a table with these samples:

First, we ask `R` where can we find leave samples in metadata:

Again, regular expressions can be used. This time, the function `grepl` will find every element in the column `metadata$class` that has the letter L, i.e. every sample from wheat leaves.

We create, as before, an object that has the information of where the samples that match the query (leave samples) are in the `metadata` table:
```{r creatin an index vector for leaves samples}
leaves.index <- which(
  grepl(
    paste0('(?=.*',
           'L',
           ')'),
    metadata$class,perl = T))
leaves.index
```
Since now we know exactly where the leaves samples are, we can subset the `metadata` table into a new `data.frame`:


```{r}
metadata.leaves <- metadata[leaves.index,]

```


## Silicon quantification in leaves samples

Since information about silicon content is needed, those rows that have no silicon content can be deleted.


```{r checking for NA in leaves}
which(is.na(metadata.leaves$Si))
which(is.na(metadata.leaves$spectra))
```
position 11 has NA both in silicon content and in index of spectra:
```{r printing position 11 in leaves}
metadata.leaves$sample[11]
```
Since sample 164 neither has silicon content nor spectra, it can be deleted:

```{r deleting sample 164}
metadata.leaves.Si <- metadata.leaves[-c(11),]
```

Then, we can extract the silicon content to a vector called `leavesSi`:

```{r creating vector with silicon content for leaves}
LeavesSi <- cbind(metadata.leaves.Si$sample,metadata.leaves.Si$Si)
```

And we can create a table with corrected mean spectra for this samples:

```{r subsetting corrected for leaves samples that have silicon content}

leavesSiSpectra <- corrected[metadata.leaves.Si$spectra.index,]
leavesSiSpectraRaw <- mean[metadata.leaves.Si$spectra.index,]
```

```{r leaves mean and corrected spectra plot,  fig.cap="\\label{fig:figs}Mean and corrected spectra for leaves samples"}
par(mfrow = c(1,2))

for (i in 1:length(
                    rownames(leavesSiSpectraRaw )
                    )
     ){

  plot(as.numeric(
                  colnames(leavesSiSpectraRaw )
                  ),
     leavesSiSpectraRaw [i,],
     xlab = '',
     ylab = '',
     axes = F,
     type = 'l',
     xlim = c(1700,400),
     ylim = c(0,0.1))
  par(new = T)
}
box()
axis(1)
axis(2)
title(main = '',
      xlab = expression(
                        paste(
                       'Wave number (cm'^'-1',
                              ')'
                              )
                        ),
      ylab = 'Absorbance (a.u.)')

par(new = F)

for (i in 1:length(
                   rownames(leavesSiSpectra)
                   )
     ){

  plot(as.numeric(
                  colnames(leavesSiSpectra)
                  ),
     leavesSiSpectra[i,],
     xlab = '',
     ylab = '',
     axes = F,
     type = 'l',
     xlim = c(1700,400),
     ylim = c(0,0.1))
  par(new = T)
}
box()
axis(1)
axis(2)
title(main = '',
      xlab = expression(
                        paste(
                       'Wave number (cm'^'-1',
                              ')'
                              )
                        ),
      ylab = 'Absorbance (a.u.)')

```


<!-- ## Covariance matrix -->


<!-- ```{r} -->

<!-- library(colorRamps) -->
<!-- library(colorspace) -->
<!-- library(viridis) -->
<!-- corleaves <- cov(leavesSiSpectra) -->

<!-- image(as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	   as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	  corleaves, -->
<!-- 	  col=viridis(100), -->
<!-- 	  axes=FALSE, -->
<!-- 	  xlab="", -->
<!-- 	  ylab="", -->
<!-- 	  xlim=c(1700,400), -->
<!-- 	   ylim=c(1700,400)) -->
<!-- contour(as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	    as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	    corleaves, -->
<!-- 	    add=TRUE, -->
<!-- 	    col="black", -->
<!-- 	    xlab="", -->
<!-- 	    ylab="", -->
<!-- 	    labcex=1.1, -->
<!-- 	    ylim=c(1700,400), -->
<!-- 	    labels="" -->
<!-- 	) -->
<!-- contour(as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	     as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	    corleaves, -->
<!-- 	    lty=0, -->
<!-- 	    labcex=1.3, -->
<!-- 	    add=TRUE, -->
<!-- 	    col="black", -->
<!-- 	    vfont=c("sans serif", "bold italic"), -->
<!-- 	    nlevels=2 -->
<!-- 	) -->

<!-- axis(1) -->
<!-- axis(2) -->
<!-- box() -->
<!-- ``` -->

## Silicon concentration
we have to create a `data.frame` to use the `plsr` function available in the `pls` package.

```{r transforming leavesSiSpectra to a matrix}
leavesSiSpectra <- as.matrix(leavesSiSpectra)
SiTable <- data.frame(Si = I(metadata.leaves.Si$Si),spectra = I(leavesSiSpectra) )
newRange <-   leavesSiSpectra[,c(261:676)]
colnames( leavesSiSpectra[,c(261,676)])
```

## modelling

The package `mdatools` can be used to perform the pls modelling with this data.


```{r}
library(mdatools)

LeavesPLS <- pls(leavesSiSpectra,
                 SiTable$Si,
                 10,
                
                 cv =1)

```

Then, we can check for 

```{r}
summary(LeavesPLS)
```
```{r}
summary(LeavesPLS$res$cal)
```

```{r}

plot(LeavesPLS)
```



```{r}

par(mfrow=c(2,2))
plotXVariance(LeavesPLS)
plotXCumVariance(LeavesPLS)
plotYVariance(LeavesPLS)
plotYCumVariance(LeavesPLS)

```

<!-- # genetic algorithm  -->

<!-- ```{r} -->
<!-- library(plsVarSel) -->
<!-- gaVarSel <- ga_pls(SiTable$Si,  -->
<!--                    leavesSiSpectra,  -->
<!--                    GA.threshold = 10,  -->
<!--                    iters = 5,  -->
<!--                    popSize = 100) -->


<!-- ``` -->


<!-- ```{r} -->
<!-- gaLeavesPLS <-pls(newRange[,unlist(gaVarSel)], -->
<!--                  SiTable$Si, -->
<!--                  10, -->

<!--                  cv =1) -->
<!-- ``` -->

<!-- ```{r} -->

<!-- plot(gaLeavesPLS) -->
<!-- ``` -->

<!-- there is no enhancement of the model using the function `gapls` -->

<!-- We can use the `plsr` function available in the `pls` package, as follows: -->

<!-- ```{r} -->
<!-- library(pls) -->

<!-- SiPLS <- plsr(SiTable$Si~ newRange, -->
<!--               ncomp = 10, -->
<!--               data = SiTable, -->
<!--               validation = 'LOO') -->
<!-- ``` -->



<!-- ```{r} -->
<!-- plot(RMSEP(SiPLS),type="b",legendpos="topright") -->
<!-- ``` -->



<!-- ```{r} -->
<!-- plot(SiPLS,ncomp=4,line=TRUE) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- plot(SiPLS,plottype="scores",comps=1:4) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- barplot(explvar(SiPLS)[1:4])  -->
<!-- ``` -->


## Variable selection

```{r gen selected , cache= T}
library(subselect)
Hmat <- lmHmat(leavesSiSpectra,metadata.leaves.Si$Si)
gen <- genetic(Hmat$mat, kmin =5, kmax = 16, H= Hmat$H, r =1, crit = 'CCR12', force = T)
```


```{r PLS with gen selected variables }
library(mdatools)

LeavesPLS <- pls(leavesSiSpectra[,gen$bestsets[6,]],
                 SiTable$Si,
                 10,
                 cv =1)

plot(LeavesPLS)

```

```{r}

```

```{r}
win.graph()
par(mfrow=c(3,3))
for(j in 1:nrow(gen$bestsets)){
for (i in 1:length(rownames(leavesSiSpectra))){
plot(as.numeric(colnames(leavesSiSpectra)),
leavesSiSpectra[i,],
xlab = '',
ylab = '',
axes = F,
type = 'l',
xlim = c(1700,400),
ylim = c(0,0.06))
par(new = T)
}
box()
axis(1)
axis(2)
title(main = paste(as.character(c(4:15)[j]),'variables'),
xlab = expression(paste('Wave number (cm'^'-1',')')),
ylab = 'Absorbance (a.u.)')
abline(v = as.numeric(colnames(leavesSiSpectra)[gen$bestsets[j,]]),
col = 2,
lty = 2)
}
```


<!-- # Multiple OLS with new variables  -->

<!-- We can try and predict the silicon content in each sample using each of the models created by using que X matrix as the selected frequencies by the genetic algorithm: -->

<!-- ```{r} -->
<!-- listOfPredictions1 <- vector('list', length = nrow(gen$bestsets)) -->

<!-- listOfModels1 <- vector('list', length = nrow(gen$bestsets))  -->
<!-- ``` -->


<!-- ```{r} -->

<!-- for(i in 1:nrow(gen$bestsets)){ -->


<!--   listOfModels1[[i]] <- lm(metadata.leaves.Si$Si ~ leavesSiSpectra[,gen$bestsets[i,]], y = T, x = T) -->

<!-- } -->
<!-- ``` -->


<!-- ```{r} -->


<!-- for(i in 1:nrow(gen$bestsets)){ -->


<!--   listOfPredictions1[[i]] <- predict(listOfModels1[[i]],  newdata = as.data.frame(leavesSiSpectra[,gen$bestsets[i,]])) -->

<!-- } -->
<!-- ``` -->



<!-- ```{r} -->

<!-- for(i in 1:nrow(gen$bestsets)){ -->


<!--   listOfPredictions1[[i]] <- predict(listOfModels1[[i]],  newdata = as.data.frame(leavesSiSpectra[,gen$bestsets[i,]])) -->

<!-- } -->
<!-- ``` -->


<!-- ```{r} -->
<!-- win.graph() -->
<!-- for(i in 1:nrow(gen$bestsets)){ -->
<!-- plot(predX8Var, -->
<!-- 	 listOfPredictions1[[i]], -->
<!-- 	 xlab="Actual Si (ppm)" , -->
<!--  	 ylab="Predicted Si (ppm)", -->
<!--  	 pch=17, -->
<!--  	 cex=1.2, -->
<!--  	 col="darkorchid4", -->
<!--  	 cex.lab=1 -->

<!--  	 ) -->
<!-- abline(a=0  , b=1, col=1, lty=1, lwd=2) -->

<!-- readline('dale') -->
<!-- par(new = F) -->
<!-- } -->
<!-- ``` -->
<!-- ## Residuals -->

<!-- ```{r} -->
<!-- residualsT <- c(listOfModels1[[1]]$residuals, -->
<!--                listOfModels1[[2]]$residuals, -->
<!--                listOfModels1[[3]]$residuals, -->
<!--                listOfModels1[[4]]$residuals, -->
<!--                listOfModels1[[5]]$residuals, -->
<!--                listOfModels1[[6]]$residuals, -->
<!--                listOfModels1[[7]]$residuals, -->
<!--                listOfModels1[[8]]$residuals, -->
<!--                listOfModels1[[9]]$residuals) -->

<!-- VariablesResiduals <- c(rep(1,23), -->
<!--                         rep(2,23), -->
<!--                         rep(3,23), -->
<!--                         rep(4,23), -->
<!--                         rep(5,23), -->
<!--                         rep(6,23), -->
<!--                         rep(7,23), -->
<!--                         rep(8,23), -->
<!--                         rep(9,23) -->
<!--                       ) -->

<!-- ResidualsTable <- data.frame(Residuals = residualsT, Variables = VariablesResiduals) -->

<!-- ResidualsTable$Variables <- as.factor(ResidualsTable$Variables) -->
<!-- dp1 <- ggplot(ResidualsTable, aes(x=Variables, y= Residuals, fill=Variables)) +  -->
<!--   geom_violin(trim=FALSE)+ -->
<!--   geom_boxplot(width=0.1, fill='white')+ -->
<!--   labs(title="",x="# of variables selected", y = "Residuals (mg/kg)") -->
<!-- dp1 + scale_fill_brewer(palette="Greens") + theme_minimal() -->

<!-- ``` -->
<!-- # Significance of models -->

<!-- ```{r} -->
<!-- win.graph() -->

<!-- pValTable <- data.frame(matrix(nrow = 9, nrow = 12)) -->


<!-- summary(listOfModels1[[1]])$coefficients[,4] -->
<!-- win.graph() -->
<!-- par(mfrow = c(3,3)) -->
<!-- for(i in 1:9){ -->
<!--    barplot(summary(listOfModels1[[i]])$coefficients[,4], -->

<!--           horiz = T, -->
<!--           names.arg = c('intercept', colnames(leavesSiSpectra[,gen$bestsets[i,]]))) -->
<!--   abline(v = 0.05, lty =2) -->

<!-- } -->

<!-- ``` -->


<!-- ```{r} -->
<!-- summary(mols) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- predictions8Var <- predict(mols,  newdata = as.data.frame(leavesSiSpectra[,gen$bestsets[4,]])) -->
<!--  n -->
<!-- predY8var <- predictions8Var -->

<!-- table8bar <- data.frame(I( predX8Var),I(predY8var)) -->

<!-- lm.C <- lm(predX8Var~predY8var) -->

<!-- plot(predX8Var, -->
<!-- 	 predY8var, -->
<!-- 	 xlab="Actual Si (ppm)" , -->
<!--  	 ylab="Predicted Si (ppm)", -->
<!--  	 pch=17, -->
<!--  	 cex=1.2, -->
<!--  	 col="darkorchid4", -->
<!--  	 cex.lab=1 -->
<!--  	 ) -->
<!-- abline(a=0  , b=1, col=1, lty=1, lwd=2) -->
<!-- # legend("topleft", recta.restado, pch=pch ,col=colfin, cex=1) -->

<!-- ``` -->
<!-- ## cross validation for MOLS and selected variables -->




<!-- ```{r} -->
<!-- library(tidyverse) -->
<!-- library(caret) -->

<!-- # First we create a list of tables with the best subsets selected by the genetic algorithm -->

<!-- listOfTables <- vector('list', nrow(gen$bestsets)) -->

<!-- listOfModels <- vector('list', nrow(gen$bestsets)) -->

<!-- listOfRMSEP <- vector('list', nrow(gen$bestsets)) -->

<!-- system.time( -->
<!-- for(i in 1:nrow(gen$bestsets)){ -->

<!--  listOfTables[[i]] <- cbind(Si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]])) -->


<!--  # setting seed to generate a -->
<!-- # reproducible random sampling -->
<!-- set.seed(125) -->

<!-- # defining training control as -->
<!-- # repeated cross-validation and -->
<!-- # value of K is 10 and repetition is 100 times -->

<!-- train_control <- trainControl(method = "repeatedcv", -->
<!--                             number = 10, repeats = 100) -->

<!-- # training the model by assigning sales column -->
<!-- # as target variable and rest other column -->
<!-- # as independent variable -->

<!-- listOfModels[[i]] <- train(Si ~.,  -->
<!--                        data = listOfTables[[i]], -->
<!--                        method = "lm", -->
<!--                       trControl = train_control) -->


<!-- listOfRMSEP[[i]] <- listOfModels[[i]]$resample$RMSE -->

<!-- } -->

<!-- ) -->

<!-- RMSEP <- c(listOfRMSEP[[1]],listOfRMSEP[[2]],listOfRMSEP[[3]],listOfRMSEP[[4]],listOfRMSEP[[5]],listOfRMSEP[[6]],listOfRMSEP[[7]],listOfRMSEP[[8]],listOfRMSEP[[9]]) -->



<!-- RMSEPTable <- data.frame(RMSEP = RMSEP, variables = c(rep(4,1000),rep(5,1000),rep(6,1000),rep(7,1000),rep(8,1000),rep(9,1000),rep(10,1000),rep(11,1000),rep(12,1000))) -->

<!-- RMSEPTable$variables <- as.factor(RMSEPTable$variables) -->


<!-- # # R program to implement -->
<!-- # # repeated K-fold cross-validation -->
<!-- #   -->
<!-- # # setting seed to generate a -->
<!-- # # reproducible random sampling -->
<!-- # set.seed(125) -->
<!-- #   -->
<!-- # # defining training control as -->
<!-- # # repeated cross-validation and -->
<!-- # # value of K is 10 and repetation is 3 times -->
<!-- # train_control <- trainControl(method = "repeatedcv", -->
<!-- #                             number = 10, repeats = 3) -->
<!-- #   -->
<!-- # # training the model by assigning sales column -->
<!-- # # as target variable and rest other column -->
<!-- # # as independent variable -->
<!-- # model <- train(Si ~., data = marketing, -->
<!-- #                method = "lm", -->
<!-- #                trControl = train_control) -->
<!-- #   -->
<!-- # # printing model performance metrics -->
<!-- # # along with other details -->
<!-- # print(model) -->
<!-- ``` -->



<!-- ```{r cross validation graph} -->


<!-- dp <- ggplot(RMSEPTable, aes(x=variables, y=RMSEP, fill=variables)) +  -->
<!--   geom_violin(trim=FALSE)+ -->
<!--   geom_boxplot(width=0.1, fill='white')+ -->
<!--   labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)") -->
<!-- dp + scale_fill_brewer(palette="Blues") + theme_minimal() -->



<!-- ``` -->

<!-- # NIST Apple Leaves Reference material infrared spectra -->




<!-- ## Importing data -->

<!-- ```{r} -->
<!-- namesNIST <- list.files(path = "./AppleLeaves",pattern = '.CSV') -->
<!-- spectra.listNIST <- lapply(paste0('./AppleLeaves/',namesNIST), read.csv, header = F) -->
<!-- wavenumbersNIST <- unlist(spectra.listNIST[[1]][1]) -->
<!-- spectra.list2NIST <- lapply(spectra.listNIST, '[', 2) -->
<!-- spectra.dfNIST <- as.data.frame(t(as.data.frame(spectra.list2NIST))) -->
<!-- rownames(spectra.dfNIST) <- namesNIST -->
<!-- colnames(spectra.dfNIST) <- wavenumbersNIST -->



<!-- ``` -->


<!-- ## plotting initial data for NIST samples -->

<!-- ```{r} -->
<!-- for(i in  1:length(rownames(spectra.dfNIST))){ -->

<!--   plot(wavenumbersNIST, -->
<!--     spectra.dfNIST[i,], -->
<!--     axes = F, -->
<!--     xlab = '',  -->
<!--     ylab = '', -->
<!--     xlim = c(4000, 400), -->
<!--     ylim= c(0,0.2), -->
<!--     type = 'l', -->
<!--     col ='black' -->

<!--   ) -->
<!--   par(new = T) -->
<!-- } -->

<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = 'raw spectra full range', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab ='absorbance (a.u.)') -->
<!-- ``` -->

<!-- ## range selection for NIST samples -->

<!-- ```{r} -->
<!-- colnames(spectra.df)[c(1,676)] -->
<!-- ``` -->
<!-- ```{r} -->
<!-- range1NIST <- spectra.dfNIST[,c(1:676)] -->
<!-- wavenumbers1NIST <- wavenumbersNIST[c(1:676)] -->
<!-- for(i in  1:length(rownames(range1NIST))){ -->

<!--   plot(wavenumbers1NIST, -->
<!--     range1NIST[i,], -->
<!--     axes = F, -->
<!--     xlab = '',  -->
<!--     ylab = '', -->
<!--     xlim = c(1700, 400), -->
<!--     ylim= c(0,0.1), -->
<!--     type = 'l', -->
<!--     col ="black" -->

<!--   ) -->
<!--   par(new = T) -->
<!-- } -->

<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = 'raw spectra - ROI', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab ='absorbance (a.u.)') -->
<!-- ``` -->

<!-- # baseline correction for NIST samples -->


<!-- ```{r} -->
<!-- library(hyperSpec) -->


<!-- spcNIST <- new('hyperSpec', -->
<!--            spc= range1NIST,  -->
<!--            wavelength = wavenumbers1NIST) -->

<!-- bendNIST <- 0.1 * wl.eval(spcNIST, -->
<!--                       function (x) x^6+x^5+x^4+x^3+x^2, -->
<!--                       normalize.wl = normalize01) -->

<!-- blNIST <- spc.rubberband(spcNIST+bendNIST, noise = 1e-4, df = 20)-bendNIST -->
<!-- sumNIST <- spcNIST+bendNIST -->
<!-- spc3NIST <- spcNIST - blNIST -->

<!-- plot(spcNIST, wl.reverse = TRUE) -->
<!-- plot(blNIST, add=TRUE, col=2,wl.reverse = TRUE) -->
<!-- plot(sumNIST,wl.reverse = TRUE) -->
<!-- plot(bendNIST, add=TRUE, col=2,wl.reverse = TRUE) -->
<!-- plot(spc3NIST,wl.reverse = TRUE) -->

<!-- corrected1NIST  <- as.data.frame(spc3NIST[1:5]) -->
<!-- correctedNIST <- as.data.frame(corrected1NIST[,1]) -->
<!-- correctedNIST <- correctedNIST + (min(correctedNIST)*-1) # shifting upwards to prevent negative values -->
<!-- ``` -->

<!-- # prediction of Si content using MOLS with variables selected by genetic algorithms -->

<!-- ```{r} -->

<!-- listOfNISTPredictions <- vector('list', length = length(listOfModels)) -->
<!-- for(i in 1:length(listOfModels)){ -->

<!--  listOfNISTPredictions[[i]] <- predict(listOfModels[[i]], newdata = as.data.frame(correctedNIST[,gen$bestsets[i,]]))  -->

<!-- } -->
<!-- ``` -->

<!-- In the list called `listOfNISTPredictions` we have the prediction fo Si content for each NIST sample. If whe reference value is 400 mg/Kg. we can calculate a relative error: -->

<!-- ```{r} -->

<!-- listOfNISTErrors <- vector('list', length = length(listOfModels)) -->
<!-- for(i in 1:length(listOfNISTPredictions)) -->
<!-- listOfNISTErrors[[i]] <- (abs(listOfNISTPredictions[[i]]-400)/400)*100 -->
<!-- ``` -->


<!-- ## PLS with new variables -->

<!-- ```{r} -->


<!-- library(pls) -->
<!-- SiPLSgen <- plsr(SiTable$Si~ leavesSiSpectra[,gen$bestsets[3,]],  -->
<!--               data = SiTable, -->
<!--               validation = 'LOO') -->


<!-- ``` -->

<!-- ```{r} -->
<!-- plot(RMSEP(SiPLSgen),type="b",legendpos="topright") -->
<!-- ``` -->


<!-- ```{r} -->
<!-- plot(SiPLS,ncomp=4,line=TRUE) -->
<!-- ``` -->









<!-- # Predicting silicon in other tissues -->
<!-- ## wheat straw -->

<!-- ### Sample selection -->

<!-- First, we ask R where can we find straw samples in `metadata` -->

<!-- ```{r} -->
<!-- straw.index <- which(grepl(paste0('(?=.*','S',')'),metadata$class,perl = T)) -->
<!-- straw.index -->
<!-- ``` -->

<!-- Now that we know where these samples are, we can separate these samples in a new  data set: -->

<!-- ```{r} -->
<!-- metadata.straw <- metadata[straw.index,] -->
<!-- head(metadata.straw) -->
<!-- ``` -->

<!-- ### preparing for quantification - deleting samples that have `NA` for spectra index -->

<!-- Here we will ask for which samples have no spectra, or silicon content. -->

<!-- ```{r} -->
<!-- which(is.na(metadata.straw$Si)) -->
<!-- which(is.na(metadata.straw$spectra)) -->
<!-- ``` -->
<!-- In the row `11`, we have a `NA` for spectra *and* for silicon content. for samples: `19`, `20`, `21` and `22` Let us inspect which samples are in these rows: -->

<!-- ```{r} -->
<!-- metadata.straw$sample[c(11,19,20,21,22)] -->
<!-- ``` -->

<!-- In order to not lose information for other analyses, we can create a new object called `metadata.strawSi` without these samples: -->


<!-- ```{r} -->
<!-- metadataStrawSi <- metadata.straw[-c(11,19,20,21,22),] -->
<!-- ``` -->

<!-- We can create a subset table with corrected mean spectra for straw samples: -->

<!-- ```{r} -->
<!-- StrawSiSpectra <- corrected[metadataStrawSi$spectra.index,] -->

<!-- for (i in 1:length(rownames(StrawSiSpectra))){ -->

<!--   plot(as.numeric(colnames(StrawSiSpectra)),  -->
<!--      StrawSiSpectra[i,], -->
<!--      xlab = '', -->
<!--      ylab = '', -->
<!--      axes = F, -->
<!--      type = 'l', -->
<!--      xlim = c(1700,400), -->
<!--      ylim = c(0,0.06)) -->
<!--   par(new = T) -->
<!-- } -->
<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = '', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab = 'Absorbance (a.u.)') -->

<!-- ``` -->


<!-- ### quantification using each of the models built with leaves data -->

<!-- pendiente, hacer matriz de correlacion con los espectros de hojas que se usaron para construir los modelos, para ver lignina - silica -->

<!-- ```{r} -->
<!-- listOfStrawPredictions <-  vector('list', length = length(listOfModels)) -->

<!-- for(i in 1:length(listOfModels)){ -->

<!--  listOfStrawPredictions[[i]] <- predict(listOfModels[[i]], newdata = as.data.frame(StrawSiSpectra[,gen$bestsets[i,]]))  -->

<!-- } -->
<!-- ``` -->

<!-- In the list called `listOfStrawPredictions` we have the prediction for Si content for each straw sample. We can calculate the difference between each of these values and the values present at `metadataStrawSi$Si`, for each model: -->

<!-- ```{r} -->
<!-- listOfStrawErrors <- vector('list', length = length(listOfModels)) -->
<!-- for(i in 1:length(listOfStrawErrors)){ -->

<!-- listOfStrawErrors[[i]] <- (abs(listOfStrawPredictions[[i]]-metadataStrawSi$Si)/metadataStrawSi$Si)*100 -->

<!-- } -->
<!-- ``` -->

<!-- we can assess the distribution of errors as follows: -->

<!-- ```{r} -->
<!-- # First, we have a list. we have to convert this list to a data.frame. with one column of errors and one column of model identifier: -->

<!-- vectorOfStrawErrors <- unlist(listOfStrawErrors) -->


<!-- StrawErrorsdf <- data.frame(error = vectorOfStrawErrors, model= as.factor(rep(4:12,each =20))) -->

<!-- dp <- ggplot(StrawErrorsdf, aes(x= model, y=error, fill=model)) +  -->
<!--   geom_violin(trim=FALSE)+ -->
<!--   geom_boxplot(width=0.1, fill='white')+ -->
<!--   labs(title="error of prediction for straw samples",x="# of variables selected", y = "relative error (n=20)") -->
<!-- dp + scale_fill_brewer(palette="Blues") + theme_minimal() + geom_hline(yintercept=100)  -->

<!-- ``` -->




<!-- ## wheat roots -->

<!-- ### Sample selection -->

<!-- First, we ask R where can we find roots samples in `metadata` -->

<!-- ```{r} -->
<!-- Roots.index <- which(grepl(paste0('(?=.*','R',')'),metadata$class,perl = T)) -->
<!-- Roots.index -->
<!-- ``` -->

<!-- Now that we know where these samples are, we can separate these samples in a new  data set: -->

<!-- ```{r} -->
<!-- metadata.Roots <- metadata[Roots.index,] -->
<!-- head(metadata.Roots) -->
<!-- ``` -->

<!-- ### preparing for quantification - deleting samples that have `NA` for spectra index -->

<!-- Here we will ask for which samples have no spectra, or silicon content. -->

<!-- ```{r} -->
<!-- which(is.na(metadata.Roots$Si)) -->
<!-- which(is.na(metadata.Roots$spectra)) -->
<!-- ``` -->
<!-- In the row `11`, we have a `NA` for spectra *and* for silicon content. for samples: `19`, `20`, `21` and `22` Let us inspect which samples are in these rows: -->

<!-- ```{r} -->
<!-- metadata.Roots$sample[c(6,8)] -->
<!-- ``` -->

<!-- In order to not lose information for other analyses, we can create a new object called `metadataRootsSi` without these samples: -->


<!-- ```{r} -->
<!-- metadataRootsSi <- metadata.Roots[-c(6,8),] -->
<!-- ``` -->

<!-- We can create a subset table with corrected mean spectra for Roots samples: -->

<!-- ```{r} -->
<!-- RootsSiSpectra <- corrected[metadataRootsSi$spectra.index,] -->

<!-- for (i in 1:length(rownames(RootsSiSpectra))){ -->

<!--   plot(as.numeric(colnames(RootsSiSpectra)),  -->
<!--      RootsSiSpectra[i,], -->
<!--      xlab = '', -->
<!--      ylab = '', -->
<!--      axes = F, -->
<!--      type = 'l', -->
<!--      xlim = c(1700,400), -->
<!--      ylim = c(0,0.06)) -->
<!--   par(new = T) -->
<!-- } -->
<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = '', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab = 'Absorbance (a.u.)') -->

<!-- ``` -->


<!-- ### quantification using each of the models built with leaves data -->

<!-- ```{r} -->
<!-- listOfRootsPredictions <-  vector('list', length = length(listOfModels)) -->

<!-- for(i in 1:length(listOfModels)){ -->

<!--  listOfRootsPredictions[[i]] <- predict(listOfModels[[i]], newdata = as.data.frame(RootsSiSpectra))  -->

<!-- } -->
<!-- ``` -->

<!-- In the list called `listOfRootsPredictions` we have the prediction for Si content for each Roots sample. We can calculate the difference between each of these values and the values present at `metadataRootsSi$Si`, for each model: -->

<!-- ```{r} -->
<!-- listOfRootsErrors <- vector('list', length = length(listOfModels)) -->
<!-- for(i in 1:length(listOfRootsErrors)){ -->

<!-- listOfRootsErrors[[i]] <- (abs(listOfRootsPredictions[[i]]-metadataRootsSi$Si)/metadataRootsSi$Si)*100 -->

<!-- } -->
<!-- ``` -->

<!-- we can assess the distribution of errors as follows: -->

<!-- ```{r} -->
<!-- # First, we have a list. we have to convert this list to a data.frame. with one column of errors and one column of model identifier: -->

<!-- vectorOfRootsErrors <- unlist(listOfRootsErrors) -->


<!-- RootsErrorsdf <- data.frame(error = vectorOfRootsErrors, model= as.factor(rep(4:12,each = 16))) -->

<!-- dp <- ggplot(RootsErrorsdf, aes(x= model, y=error, fill=model)) +  -->
<!--   geom_violin(trim=FALSE)+ -->
<!--   geom_boxplot(width=0.1, fill='white')+ -->
<!--   labs(title="error of prediction for Roots samples",x="# of variables selected", y = "relative error (n=20)") -->
<!-- dp + scale_fill_brewer(palette="Blues") + theme_minimal() + geom_hline(yintercept=100)  -->

<!-- ``` -->




<!-- # zero with ludox silica -->

<!-- ## Importing data -->

<!-- ```{r} -->
<!-- namesludox <- list.files(path = "./AppleLeaves",pattern = '.CSV') -->
<!-- spectra.listludox <- lapply(paste0('./AppleLeaves/',namesludox), read.csv, header = F) -->
<!-- wavenumbersludox <- unlist(spectra.listludox[[1]][1]) -->
<!-- spectra.list2ludox <- lapply(spectra.listludox, '[', 2) -->
<!-- spectra.dfludox <- as.data.frame(t(as.data.frame(spectra.list2ludox))) -->
<!-- rownames(spectra.dfludox) <- namesludox -->
<!-- colnames(spectra.dfludox) <- wavenumbersludox -->
<!-- ``` -->

<!-- ## plotting initial data for ludox samples -->

<!-- ```{r} -->
<!-- for(i in  1:length(rownames(spectra.dfludox))){ -->

<!--   plot(wavenumbersludox, -->
<!--     spectra.dfludox[i,], -->
<!--     axes = F, -->
<!--     xlab = '',  -->
<!--     ylab = '', -->
<!--     xlim = c(4000, 400), -->
<!--     ylim= c(0,0.2), -->
<!--     type = 'l', -->
<!--     col ='black' -->

<!--   ) -->
<!--   par(new = T) -->
<!-- } -->

<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = 'raw spectra full range', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab ='absorbance (a.u.)') -->
<!-- ``` -->


<!-- ## range selection for ludox samples -->

<!-- ```{r} -->
<!-- colnames(spectra.df)[c(1,676)] -->
<!-- ``` -->
<!-- ```{r} -->
<!-- range1ludox <- spectra.dfludox[,c(1:676)] -->
<!-- wavenumbers1ludox <- wavenumbersludox[c(1:676)] -->
<!-- for(i in  1:length(rownames(range1ludox))){ -->

<!--   plot(wavenumbers1ludox, -->
<!--     range1ludox[i,], -->
<!--     axes = F, -->
<!--     xlab = '',  -->
<!--     ylab = '', -->
<!--     xlim = c(1700, 400), -->
<!--     ylim= c(0,0.1), -->
<!--     type = 'l', -->
<!--     col ="black" -->

<!--   ) -->
<!--   par(new = T) -->
<!-- } -->

<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = 'raw spectra - ROI', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab ='absorbance (a.u.)') -->
<!-- ``` -->



<!-- # baseline correction for ludox samples -->


<!-- ```{r} -->
<!-- library(hyperSpec) -->


<!-- spcludox <- new('hyperSpec', -->
<!--            spc= range1ludox,  -->
<!--            wavelength = wavenumbers1ludox) -->

<!-- bendludox <- 0.1 * wl.eval(spcludox, -->
<!--                       function (x) x^6+x^5+x^4+x^3+x^2, -->
<!--                       normalize.wl = normalize01) -->

<!-- blludox <- spc.rubberband(spcludox+bendludox, noise = 1e-4, df = 20)-bendludox -->
<!-- sumludox <- spcludox+bendludox -->
<!-- spc3ludox <- spcludox - blludox -->

<!-- plot(spcludox, wl.reverse = TRUE) -->
<!-- plot(blludox, add=TRUE, col=2,wl.reverse = TRUE) -->
<!-- plot(sumludox,wl.reverse = TRUE) -->
<!-- plot(bendludox, add=TRUE, col=2,wl.reverse = TRUE) -->
<!-- plot(spc3ludox,wl.reverse = TRUE) -->

<!-- corrected1ludox  <- as.data.frame(spc3ludox[1:5]) -->
<!-- correctedludox <- as.data.frame(corrected1ludox[,1]) -->
<!-- correctedludox <- correctedludox + (min(correctedludox)*-1) # shifting upwards to prevent negative values -->
<!-- ``` -->



<!-- # Classification -->

<!-- In order to use classification algorithms, we can create a new dataset without missing values in `metadata$spectra`, `metadata$class`, and `metadata$Si`  -->

<!-- ```{r} -->
<!-- which(is.na(metadata$spectra)) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- which(is.na(metadata$class)) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- which(is.na(metadata$Si)) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- unique( -->
<!--           c( which(is.na(metadata$spectra)), -->
<!--              which(is.na(metadata$class)), -->
<!--              which(is.na(metadata$Si))) -->
<!--        ) -->

<!-- missing <- unique( -->
<!--           c( which(is.na(metadata$spectra)), -->
<!--              which(is.na(metadata$class)), -->
<!--              which(is.na(metadata$Si))) -->
<!--        ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- metadata.class <- metadata[-missing,] -->
<!-- ``` -->

<!-- ## Hierarchical clustering and k-means -->


