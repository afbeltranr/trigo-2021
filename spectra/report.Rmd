---
title: "The structure and interaction of silica in plant cell walls: Data analysis report"
author: "Felipe Beltran"
date: "6/16/2021"
output:
    pdf_document
fig_caption: yes
---

# Introduction

In this document we will save all data manipulation and analysis related to the infrared spectra from the project: **The structure and interaction of silica in plant cell walls**


# Loading data into `R`

First, we create an object called `names`, which is a `list`, in which we will save the names of the files with the `.CSV` extension contained in [this](https://github.com/pipoelpipas/trigo-2021/tree/main/spectra) folder.

```{r creating names list}
names <- list.files(pattern = '.CSV')
```

Then, we use the function `lapply` to apply the function `read.csv` to each element of the list `names` and then save each of the `data.frames` from the files in to R.
```{r reading each data frame}
spectra.list <- lapply(names, read.csv, header = F)
```

Now, se can save the frequencies of incident light as a vector called `wavenumbers`. The code `spectra.list[[1]][1]` selects the first element of the list `spectra.list` using the index operator for lists `[[1]]`, which is a `data.frame`. Then, we select the first column of that `data.frame` using the index operator `[1]`:


```{r extracting wave numbers}
wavenumbers <- unlist(spectra.list[[1]][1])
```

The object `wavenumbers` has 1 row and 1869 columns, each column is one of the frequencies used by the spectrometer in the experiment.

As we did previously, we can use again the function `lapply` to apply the index operator `[` and select ONLY the second column of each `data.frame` that has inside the absorbance at each frequency.

```{r extracting just absorbances}
spectra.list2 <- lapply(spectra.list, '[', 2)
```

In order to make data easier to manipulate, we can transform the list of columns called `spectra.list2` into a `data.frame` as follows:

```{r converting list of df to one df}
spectra.df <- as.data.frame(t(as.data.frame(spectra.list2)))
```

the object `spectra.df` has 318 rows, i.e. 318 spectra from different samples and 1869 columns, or infrared frequencies.

Since the function `t()` transforms `data.frame` class objects into `matrix` class objects, we have to assign again to `spectra.df` (a matrix) the corresponding column and row names:

```{r assigning names 1}
rownames(spectra.df) <- names
colnames(spectra.df) <- wavenumbers
# gsub('.{6}$', '', names)

```

## Tidying up the `data.frame`


Since the names of the sample right now have the following structure:

```{r checking names}
head(names)
```


We can get rid of the unnecessary characters in the names of the samples, such as the extension and other symbols such as `"` or `.`. For that we can use the function `gsub()` and `regex` or regular expressions in order to replace these symbols for nothing, or `''`.

The regular expression for this replacement is built as follows:

* `.` matches any element that complies with the requirement, or applies the query to every element
* `{4}` replaces characters by `''` exactly 4 times
* `$` matches the end of each name

That is described before allows us to tell `R` that we want to replace the last 4 characters in each name by nothing, or `''`.

```{r correcting names length}
names2 <- gsub('.{4}$', '', rownames(spectra.df))
head(names2)
```
There are some samples that have longer names, such as:

```{r checking names 2}
head(names2[292:318])
```
We can also save just the information that is useful for displaying in tables and plots:

```{r correcting names length 2}
names2[292:318] <- gsub('.{41}$', '', rownames(spectra.df)[292:318])
head(names2[292:318])
```
Finally, we assign the curated names to our data frame, `spectra.df`

```{r assigning corrected names}
rownames(spectra.df) <- names2
```


# Plotting intial data

Since we have joined several spectra from different samples, we can try to visualize what we are dealing with. 

Knowing that we have already the names of the samples, it would be handy if we used a factor that helped us to differentiate replicas of experiments:

```{r creating factor for coloring replicas}
cols <- factor(gsub('.{2}$', '', names2))
head(cols)
```
If we use the factor `cols`, we can plot three replicas of one sample using the same color

Now, we can use a loop to plot each one of the rows of our `data.frame`: 

```{r raw data plot, fig.cap="\\label{fig:figs}raw spectra of triplicated samples"}

for(i in  1:length(rownames(spectra.df))){
  
  plot(wavenumbers,
    spectra.df[i,],
    axes = F,
    xlab = '', 
    ylab = '',
    xlim = c(4000, 400),
    ylim= c(0,0.2),
    type = 'l',
    col =cols[i]

  )
  par(new = T)
}

box()
axis(1)
axis(2)
title(main = '',
      xlab = expression(paste('Wave number (cm'^'-1',')')),
      ylab ='absorbance (a.u.)')
```

As we can see in Figure \ref{fig:figs} In the range between 2500 and 2000 cm-1 variability due to experimental noise and background correction is present. In order to use multivariate methods and extract the chemical information from the dataset, we can select a region of interest (ROI) in which we take into account characteristic bands for molecules which concentration can be different between samples, such as silicon oxides, or lignin monomers.

# range selection

Now, we can check for where is that ROI in our data frame. Since the frequencies are arranged along the columns, we can search for the columns that have column names between 1700 and 400 $cm^{-1}$

```{r revision of the column position for ROI }
colnames(spectra.df)[c(1,676)]
```
Once we know where the ROI is in the data frame, we can create a subset called `range1` to store the spectra of all samples within this range, and plot it:

```{r ROI selection}
range1 <- spectra.df[,c(1:676)]
wavenumbers1 <- wavenumbers[c(1:676)]
```

```{r ROI plot, fig.cap="\\label{fig:figs}ROI spectra of triplicated samples"}
for(i in  1:length(rownames(range1))){

  plot(wavenumbers1,
    range1[i,],
    axes = F,
    xlab = '',
    ylab = '',
    xlim = c(1700, 400),
    ylim= c(0,0.2),
    type = 'l',
    col =cols[i]

  )
  par(new = T)
}

box()
axis(1)
axis(2)
title(main = 'raw spectra - ROI',
      xlab = expression(paste('Wave number (cm'^'-1',')')),
      ylab ='absorbance (a.u.)')

```


# mean spectra calculation

Since each sample has three replicated spectra, we can calculate the mean of each three samples as follows:


* First, we create a vector to tell R which samples to look for. Using the function `unique()` we extract the unique values without taking their repetitions:

```{r search vector}
search.vector <- unique(unlist(cols))
head(search.vector)
```
Once we have the names for each sample, we can search for $\dfrac{318}{3}=106$ triads of samples. Once we know where they are, we can calculate the mean for each three replicates.

First, we create a list in which we are going to save the position of each three spectra:

```{r creating index list for means}
index <- list(106)
```


Now we can again use the help of regular expressions to search for every sample that matches with one single sample:

As an example:

The regular expression that we will use this time is `(?=.*<search>)` where `<search>` is replaced with the sample's name.

This will find any element for the vector `rownames(spectra.df)` that matches with the character in `search vector`. For example, if we search for the first sample, `search.vector[1]` which is sample `125`:

```{r first sample name}
as.character(search.vector[1]) # the name of the first sample
```
The search will tell us the positions in `rownames(spectra.df)` where where we can find the character `'125'` 

```{r regex for means example}
 which(
   grepl(
     paste0('(?=.*',as.character(search.vector[1]),')'),
     rownames(spectra.df),
     perl=T
     ) 
   )
```
Then we can confirm:

```{r checking regex for means}
rownames(spectra.df)[c(1, 2, 3)]
```

This process can be automated using a `for` loop in R:

```{r seaching for means using regex}

for (i in 1:106){

  index[[i]] <- which(
    grepl(
      paste0('(?=.*',as.character(search.vector[i]),')'),
                       rownames(spectra.df),
                       perl=T
                       )
                 )
}
```

```{r checking for results of regex search}
search.vector[2]
rownames(spectra.df)[c(index[[2]])]
```


Once we know where each triplicate is, we can proceed to calculate the means:

* First, we create a matrix to save the mean spectra that will result from the calculation. 

```{r creation of mean matrix}
mean <- matrix(ncol= ncol(range1),
               nrow = nrow(range1)/3)
```

*Then, we assign to this empty matrix, `mean`, its corresponding column and row names:

```{r asigning dimnames to mean}
# mean <- as.data.frame(mean)

colnames(mean) <- colnames(range1)
rownames(mean) <- search.vector
```


Then we can loop through columns indexing each wave number, one after another, in each iteration of the loop, or each time `j` changes its value. Posibles values for `j` are defined when `in 1:length(ncol(range1))`. where `ncol` gives us the number of columns of `range1` or the number of wave numbers present along the ROI.

At the same time, `i` takes values at each one of the numbers present between `1` and `nrow(mean)`

at step 1 in both loops, we save in the position `mean[1,1]` the resulting value when we use the function `mean()` which as default calculates the arithmetic mean (when the argument trim = 0 is given as default, the function trims a fraction of 0 observations from each end of the three observations before the means is computed.)

In order to calculate this mean estimator from a sample of 3 replicates, we index the spectral matrix `range1` in three special positions for each sample, those found in the creation of the  `index` list. 

In this step of the calculation, the first value of absorbance for the sample 125 at wave number 399.1, is empty, as are all the other slots of this matrix.

```{r checking initial state of mean}
mean[1,1]
```

for example, for the first sample, and the first wave number, we will save the result of the calculation of the mean of three replicas of sample 125, and at a wave number of 399.1, `mean[1,1]`.In order to accomplish this, we select the first position of the list `index[[1]]`:

```{r showing where the 3 replicas for 125 are}
index[[1]]

```

when we print the content of this position of the list, we can notice that the samples `125-1` `125-2` and `125-3` lie in the positions 1, 2, and 3 respectively of the data.frame `range1`.

So the calculation will be applied to `range1[index[[1]][1],1]`, `range1[index[[1]][2],1]` and `range1[index[[1]][2],1]`, or rows 1, 2, and 3. 

the process is then repeated through all of the wave numbers (columns) and samples (rows) of the data set.

```{r calculating the means}

for(j in 1:ncol(range1)){

for(i in 1:nrow(mean)){

mean[i,j] <- mean(c(range1[index[[i]][1],j],
                    range1[index[[i]][2],j],
                    range1[index[[i]][3],j]
                      ) )
}
}
```

then we turn this matrix into a data.frame: 

```{r making mean a data frame}
mean <- as.data.frame(mean)
```

Once we have calculated the mean for each sample, we can plot the resulting mean spectra using the same factor used before, `cols` to color each sample of the same color of their triplicates.

```{r plotting the mean, fig.cap="\\label{fig:figs}Calculated mean spectra"}

cols.means <- as.factor(search.vector)

for(i in  1:length(rownames(mean))){

  plot(wavenumbers1,
    mean[i,],
    axes = F,
    xlab = '',
    ylab = '',
    xlim = c(1700, 400),
    ylim= c(0,0.135309),
    type = 'l',
    col =cols.means[i]

  )
  par(new = T)
}

box()
axis(1)
axis(2)
title(main = '',
      xlab = expression(paste('Wave number (cm'^'-1',')')),
      ylab ='absorbance (a.u.)')
```


Once we have calculated the mean estimator for each multivariate spectra, we can proceed to perform pre-treatments in order to clean the data, and extract as much as chemical information as we can.

# baseline correction

In this experiment we have performed an analogue to the the baseline correction described by [beleites et al. 2020](https://cran.r-project.org/web/packages/hyperSpec/vignettes/baseline.pdf):

```{r loading hyperspec, message= FALSE}
library(hyperSpec) 
# hyperSpec package functions and 
#data is charged in this session
```

We create an object that can be identified and manipulated by the functions of `hyperSpec` package.

```{r saving spectra into hyperSpec object }
spc <- new('hyperSpec', # The class of the object
           spc= mean, # the spectra matrix
           wavelength = wavenumbers1) # independent variable, whether wave number 
#or wave length

```

then in an object called `bend`,  we can save the result of `wl.eval` applied to `spc`. This function generates a baseline 'reference spectra':

```{r calculation of bend reference spectra}
bend <- 0.1 * wl.eval(spc,
                      function (x) x^6+x^5+x^4+x^3+x^2,
                      normalize.wl = normalize01)

```

*   `function (x) x^6+x^5+x^4+x^3+x^2` defines a polynomial that is used to fit the baselines to the supporting points in the lower region of the spectra contained in 'spc', using this functions the baseline 'reference spectra' is calculated 
     
* `normalize.wl=normalize01` is a function used to transform the wave numbers before evaluating the polynomial. using `normalize01` we map the range of each wave number to the interval $[0,1]$ 

* the multiplication by $0.1$ is the normalization chosen for these spectra.

Now we can use the `rubberband` method to estimate the baseline. Setting the noise to $1\cdot10^{-4}$ allows us to take advantage of the low noise presented for this spectra. (a noise of `noise=4` sets an interval of 2 times standard deviations).

```{r baseline calculation}
bl <- spc.rubberband(spc+bend, noise = 1e-4, df = 20)-bend
```

The base-line correction method selected for this work is one of many, and tuning the correction parameters can be subject to a design of experiments, using as a response variable a quality measure of the analysis that is going to be performed after the correction. For example $Q^2$ for PCA, or $R_{adj}$ and $RMSEP_{CV}$ for multiple linear regression models as suggested by [hovde 2010](https://doi.org/10.1366/000370210792434350). 

Now, we can visualize the results of these baseline corrections.

First, the spectra before correction and the estimated baseline 'reference spectra':

```{r baseline plot 1, fig.cap="\\label{fig:figs}Mean spectra and rubberband baseline"}
labels (spc, ".wavelength") <- expression(paste('Wave number (cm'^'-1',')'))
labels (spc, "spc") <- expression(paste('Absorbance (a.u.)'))

plot(spc, wl.reverse = TRUE)
plot(bl, add=TRUE, col=2,wl.reverse = TRUE)
``` 

And the hearth of the rubberband method, the bending of the spectra to add support points in the convex part of the spectra:

```{r baseline plot 2 bend, fig.cap="\\label{fig:figs}bent mean spectra and bent baseline"}

sum <- spc+bend
plot(sum,wl.reverse = TRUE)
plot(bend, add=TRUE, col=2,wl.reverse = TRUE)
```

Then, the corrected spectra, which is calculated by substracting the baseline `bl` from the spectra `spc`:


```{r baseline plot 3 corrected, fig.cap="\\label{fig:figs}baseline corrected mean spectra"}
spc3 <- spc - bl
spc3 <- spc3 + (min(spc3)*-1)# We add the minimum value
#which is negative to have only positive values
plot(spc3,wl.reverse = TRUE)

```

Now, we can extract the corrected spectra from the `hyperSpec` object and save it as a `data.frame` to handle the information in an easier way later.
```{r}
corrected1  <- as.data.frame(spc3[1:106])
corrected <- as.data.frame(corrected1[,1])
corrected <- corrected + (min(corrected)*-1) # shifting upwards to prevent negative values
```

Up to this point, we have calculated the mean spectra and corrected the base-line of each spectrum. 


# multiplicative scatter correction (MSC)

Since This is a popular pre-treatment [Rinnan 2009]()                       
<!-- ```{r} -->
<!-- library(pls) -->
<!-- correctedMSC <- msc(as.matrix(corrected)) -->



<!-- for (i in 1:length(rownames(correctedMSC))){ -->

<!--   plot(as.numeric(colnames(correctedMSC)),  -->
<!--      correctedMSC[i,], -->
<!--      xlab = '', -->
<!--      ylab = '', -->
<!--      axes = F, -->
<!--      type = 'l', -->
<!--      xlim = c(1700,400), -->
<!--      ylim = c(0,0.06)) -->
<!--   par(new = T) -->
<!-- } -->
<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = '', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab = 'Absorbance (a.u.)') -->
<!-- ``` -->

<!-- ```{r ,echo = FALSE} -->
<!-- # par(mfrow = c(2,2)) -->
<!-- #  -->
<!-- # for(i in  1:length(rownames(spectra.df))){ -->
<!-- #    -->
<!-- #   plot(wavenumbers, -->
<!-- #     spectra.df[i,], -->
<!-- #     axes = F, -->
<!-- #     xlab = '',  -->
<!-- #     ylab = '', -->
<!-- #     xlim = c(4000, 400), -->
<!-- #     ylim= c(0,0.2), -->
<!-- #     type = 'l', -->
<!-- #     col =cols[i] -->
<!-- #  -->
<!-- #   ) -->
<!-- #   par(new = T) -->
<!-- # } -->
<!-- #  -->
<!-- # box() -->
<!-- # axis(1) -->
<!-- # axis(2) -->
<!-- # title(main = 'raw spectra full range', -->
<!-- #       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!-- #       ylab ='absorbance (a.u.)') -->
<!-- #  -->
<!-- # for(i in  1:length(rownames(range1))){ -->
<!-- #    -->
<!-- #   plot(wavenumbers1, -->
<!-- #     range1[i,], -->
<!-- #     axes = F, -->
<!-- #     xlab = '',  -->
<!-- #     ylab = '', -->
<!-- #     xlim = c(1700, 400), -->
<!-- #     ylim= c(0,0.2), -->
<!-- #     type = 'l', -->
<!-- #     col =cols[i] -->
<!-- #  -->
<!-- #   ) -->
<!-- #   par(new = T) -->
<!-- # } -->
<!-- #  -->
<!-- # box() -->
<!-- # axis(1) -->
<!-- # axis(2) -->
<!-- # title(main = 'raw spectra - ROI', -->
<!-- #       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!-- #       ylab ='absorbance (a.u.)') -->
<!-- #  -->
<!-- #  -->
<!-- # for(i in  1:length(rownames(mean))){ -->
<!-- #    -->
<!-- #   plot(wavenumbers1, -->
<!-- #     mean[i,], -->
<!-- #     axes = F, -->
<!-- #     xlab = '',  -->
<!-- #     ylab = '', -->
<!-- #     xlim = c(1700, 400), -->
<!-- #     ylim= c(0,0.2), -->
<!-- #     type = 'l', -->
<!-- #     col =cols.means[i] -->
<!-- #  -->
<!-- #   ) -->
<!-- #   par(new = T) -->
<!-- # } -->
<!-- #  -->
<!-- # box() -->
<!-- # axis(1) -->
<!-- # axis(2) -->
<!-- # title(main = 'averaged spectra', -->
<!-- #       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!-- #       ylab ='absorbance (a.u.)') -->
<!-- #  -->
<!-- # for(i in  1:length(rownames(mean))){ -->
<!-- #    -->
<!-- #   plot(wavenumbers1, -->
<!-- #     corrected[i,], -->
<!-- #     axes = F, -->
<!-- #     xlab = '',  -->
<!-- #     ylab = '', -->
<!-- #     xlim = c(1700, 400), -->
<!-- #     ylim= c(0,0.1), -->
<!-- #     type = 'l', -->
<!-- #     col =cols.means[i] -->
<!-- #  -->
<!-- #   ) -->
<!-- #   par(new = T) -->
<!-- # } -->
<!-- #  -->
<!-- # box() -->
<!-- # axis(1) -->
<!-- # axis(2) -->
<!-- # title(main = 'corrected spectra', -->
<!-- #       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!-- #       ylab ='absorbance (a.u.)') -->

<!-- ``` -->


<!-- # metadata -->


<!-- First, we load the metadata table, created from the data table 'Datos_para_colombia.xlsx': -->

<!-- ```{r} -->
<!-- library(readxl) -->
<!-- metadata <- read_excel("metadata.xlsx") -->
<!-- which(is.na(metadata$sample)) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- metadata <- metadata[-c(17),] -->
<!-- which(is.na(metadata$sample)) -->
<!-- ``` -->

<!-- ## matching samples that have metadata with samples with spectra -->

<!-- ```{r} -->

<!-- positions <- vector('list', 87) # the same sizeas metadata$sample -->

<!-- for (i in 1:87){ -->

<!-- positions[[i]] <- which(grepl(paste0('(?=.*',as.character(metadata$sample[i]),')'),rownames(corrected), perl=T))  -->
<!-- } -->


<!-- ``` -->

<!-- In the list `positions` we know where can we find the corrected mean spectra for each sample identified in `metadata$sample`. For instance, for `metadata$sample[1]`: -->

<!-- ```{r} -->
<!-- metadata$sample[1] -->
<!-- ``` -->
<!-- we have in `positions`, where can we find the spectra for sample 125: -->

<!-- ```{r} -->
<!-- rownames(corrected)[positions[[1]]] -->
<!-- ``` -->
<!-- Now, we can create a new column in metadata, to state which sample has spectra: -->

<!-- ```{r} -->
<!-- for(i in 1:length(metadata$sample)) { -->

<!--   if(length(positions[[i]]) == 1){ -->

<!--     metadata$spectra[i] <- rownames(corrected)[positions[[i]]] -->
<!--   }else{ -->
<!--     metadata$spectra[i] <- NA -->
<!--   } -->

<!-- } -->

<!-- compare <- data.frame(metadata = metadata$sample, spectra = metadata$spectra) -->
<!-- ``` -->

<!-- Also we can add an index column for when we need to call spectra from `corrected` -->
<!-- Now we know what we have of each sample, as far as composition and spectra are concerned. -->

<!-- ```{r} -->
<!-- for(i in 1:length(metadata$sample)) { -->

<!--   if(length(positions[[i]]) == 1){ -->

<!--     metadata$spectra.index[i] <- positions[[i]] -->
<!--   }else{ -->
<!--     metadata$spectra.index[i] <- NA -->
<!--   } -->

<!-- } -->
<!-- ``` -->

<!-- # Leaves selection -->
<!-- ## Selection of samples -->

<!-- prior work indicates that leave samples presented more variability thus it is worth it to subset a table with these samples: -->

<!-- First, we ask `R` where can we find leave samples in metadata: -->

<!-- ```{r} -->
<!-- leaves.index <- which(grepl(paste0('(?=.*','L',')'),metadata$class,perl = T)) -->
<!-- leaves.index -->
<!-- ``` -->
<!-- Now that we know, we can separate these samples in a new  data set -->

<!-- ```{r} -->
<!-- metadata.leaves <- metadata[leaves.index,] -->
<!-- head(metadata.leaves) -->
<!-- ``` -->


<!-- ## Silicon quantification in leaves samples -->

<!-- Now, we can delete the rows (samples) that have no spectra, or silicon content. -->

<!-- ```{r} -->
<!-- which(is.na(metadata.leaves$Si)) -->
<!-- which(is.na(metadata.leaves$spectra)) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- metadata.leaves$sample[11] -->
<!-- ``` -->
<!-- Now we can delete the sample `164`, since it does not have silicon content nor spectra. -->

<!-- ```{r} -->
<!-- metadata.leaves.Si <- metadata.leaves[-c(11),] -->
<!-- ``` -->

<!-- Then, we can extrat the silicon content to a vector called `leavesSi`: -->

<!-- ```{r} -->
<!-- LeavesSi <- cbind(metadata.leaves.Si$sample,metadata.leaves.Si$Si) -->
<!-- ``` -->

<!-- And we can create a table with corrected mean spectra for this samples: -->

<!-- ```{r} -->

<!-- win.graph() -->
<!-- leavesSiSpectra <- corrected[metadata.leaves.Si$spectra.index,] -->
<!-- leavesSiSpectraRaw <- mean[metadata.leaves.Si$spectra.index,]  -->

<!-- par(mfrow = c(1,2)) -->

<!-- for (i in 1:length(rownames(leavesSiSpectraRaw ))){ -->

<!--   plot(as.numeric(colnames(leavesSiSpectraRaw )),  -->
<!--      leavesSiSpectraRaw [i,], -->
<!--      xlab = '', -->
<!--      ylab = '', -->
<!--      axes = F, -->
<!--      type = 'l', -->
<!--      xlim = c(1700,400), -->
<!--      ylim = c(0,0.1)) -->
<!--   par(new = T) -->
<!-- } -->
<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = '', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab = 'Absorbance (a.u.)') -->

<!-- par(new = F) -->

<!-- for (i in 1:length(rownames(leavesSiSpectra))){ -->

<!--   plot(as.numeric(colnames(leavesSiSpectra)),  -->
<!--      leavesSiSpectra[i,], -->
<!--      xlab = '', -->
<!--      ylab = '', -->
<!--      axes = F, -->
<!--      type = 'l', -->
<!--      xlim = c(1700,400), -->
<!--      ylim = c(0,0.1)) -->
<!--   par(new = T) -->
<!-- } -->
<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = '', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab = 'Absorbance (a.u.)') -->

<!-- ``` -->


<!-- ## Covariance matrix -->


<!-- ```{r} -->

<!-- library(colorRamps) -->
<!-- library(colorspace) -->
<!-- library(viridis) -->
<!-- corleaves <- cov(leavesSiSpectra) -->

<!-- image(as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	   as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	  corleaves, -->
<!-- 	  col=viridis(100), -->
<!-- 	  axes=FALSE, -->
<!-- 	  xlab="", -->
<!-- 	  ylab="", -->
<!-- 	  xlim=c(1700,400), -->
<!-- 	   ylim=c(1700,400)) -->
<!-- contour(as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	    as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	    corleaves, -->
<!-- 	    add=TRUE, -->
<!-- 	    col="black", -->
<!-- 	    xlab="", -->
<!-- 	    ylab="", -->
<!-- 	    labcex=1.1, -->
<!-- 	    ylim=c(1700,400), -->
<!-- 	    labels="" -->
<!-- 	) -->
<!-- contour(as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	     as.numeric(colnames(leavesSiSpectra)), -->
<!-- 	    corleaves, -->
<!-- 	    lty=0, -->
<!-- 	    labcex=1.3, -->
<!-- 	    add=TRUE, -->
<!-- 	    col="black", -->
<!-- 	    vfont=c("sans serif", "bold italic"), -->
<!-- 	    nlevels=2 -->
<!-- 	) -->

<!-- axis(1) -->
<!-- axis(2) -->
<!-- box() -->
<!-- ``` -->


<!-- ## Silicon concentration -->

<!-- we have to create a `data.frame` in order to use the `plsr` function available in the `pls` package. -->

<!-- ```{r} -->

<!-- leavesSiSpectra <- as.matrix(leavesSiSpectra) -->
<!-- SiTable <- data.frame(Si = I(metadata.leaves.Si$Si),spectra = I(leavesSiSpectra) ) -->
<!-- nuevoRango <-   leavesSiSpectra[,c(261:676)] -->
<!-- colnames( leavesSiSpectra[,c(261,676)]) -->
<!-- ``` -->

<!-- ## model -->

<!-- ```{r} -->
<!-- library(pls) -->
<!-- SiPLS <- plsr(SiTable$Si~ msc(nuevoRango),  -->
<!--               ncomp = 10, -->
<!--               data = SiTable, -->
<!--               validation = 'LOO') -->
<!-- ``` -->



<!-- ```{r} -->
<!-- plot(RMSEP(SiPLS),type="b",legendpos="topright") -->
<!-- ``` -->



<!-- ```{r} -->
<!-- plot(SiPLS,ncomp=4,line=TRUE) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- plot(SiPLS,plottype="scores",comps=1:4) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- barplot(explvar(SiPLS)[1:4])  -->
<!-- ``` -->


<!-- ## Variable selection -->

<!-- ```{r} -->
<!-- library(subselect) -->
<!-- Hmat <- lmHmat(leavesSiSpectra,metadata.leaves.Si$Si) -->
<!-- gen <- genetic(Hmat$mat, kmin =4, kmax = 12, H= Hmat$H, r =1, crit = 'CCR12', force = T) -->
<!-- ``` -->




<!-- ```{r} -->
<!-- win.graph() -->
<!-- par(mfrow=c(3,3)) -->
<!-- for(j in 1:nrow(gen$bestsets)){ -->
<!-- for (i in 1:length(rownames(leavesSiSpectra))){ -->
<!-- plot(as.numeric(colnames(leavesSiSpectra)), -->
<!-- leavesSiSpectra[i,], -->
<!-- xlab = '', -->
<!-- ylab = '', -->
<!-- axes = F, -->
<!-- type = 'l', -->
<!-- xlim = c(1700,400), -->
<!-- ylim = c(0,0.06)) -->
<!-- par(new = T) -->
<!-- } -->
<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = paste(as.character(c(4:15)[j]),'variables'), -->
<!-- xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!-- ylab = 'Absorbance (a.u.)') -->
<!-- abline(v = as.numeric(colnames(leavesSiSpectra)[gen$bestsets[j,]]), -->
<!-- col = 2, -->
<!-- lty = 2) -->
<!-- } -->
<!-- ```   -->


<!-- # Multiple OLS with new variables  -->

<!-- We can try and predict the silicon content in each sample using each of the models created by using que X matrix as the selected frequencies by the genetic algorithm: -->

<!-- ```{r} -->
<!-- listOfPredictions1 <- vector('list', length = nrow(gen$bestsets)) -->

<!-- listOfModels1 <- vector('list', length = nrow(gen$bestsets))  -->
<!-- ``` -->


<!-- ```{r} -->

<!-- for(i in 1:nrow(gen$bestsets)){ -->


<!--   listOfModels1[[i]] <- lm(metadata.leaves.Si$Si ~ leavesSiSpectra[,gen$bestsets[i,]], y = T, x = T) -->

<!-- } -->
<!-- ``` -->


<!-- ```{r} -->


<!-- for(i in 1:nrow(gen$bestsets)){ -->


<!--   listOfPredictions1[[i]] <- predict(listOfModels1[[i]],  newdata = as.data.frame(leavesSiSpectra[,gen$bestsets[i,]])) -->

<!-- } -->
<!-- ``` -->



<!-- ```{r} -->

<!-- for(i in 1:nrow(gen$bestsets)){ -->


<!--   listOfPredictions1[[i]] <- predict(listOfModels1[[i]],  newdata = as.data.frame(leavesSiSpectra[,gen$bestsets[i,]])) -->

<!-- } -->
<!-- ``` -->


<!-- ```{r} -->
<!-- win.graph() -->
<!-- for(i in 1:nrow(gen$bestsets)){ -->
<!-- plot(predX8Var, -->
<!-- 	 listOfPredictions1[[i]], -->
<!-- 	 xlab="Actual Si (ppm)" , -->
<!--  	 ylab="Predicted Si (ppm)", -->
<!--  	 pch=17, -->
<!--  	 cex=1.2, -->
<!--  	 col="darkorchid4", -->
<!--  	 cex.lab=1 -->

<!--  	 ) -->
<!-- abline(a=0  , b=1, col=1, lty=1, lwd=2) -->

<!-- readline('dale') -->
<!-- par(new = F) -->
<!-- } -->
<!-- ``` -->
<!-- ## Residuals -->

<!-- ```{r} -->
<!-- residualsT <- c(listOfModels1[[1]]$residuals, -->
<!--                listOfModels1[[2]]$residuals, -->
<!--                listOfModels1[[3]]$residuals, -->
<!--                listOfModels1[[4]]$residuals, -->
<!--                listOfModels1[[5]]$residuals, -->
<!--                listOfModels1[[6]]$residuals, -->
<!--                listOfModels1[[7]]$residuals, -->
<!--                listOfModels1[[8]]$residuals, -->
<!--                listOfModels1[[9]]$residuals) -->

<!-- VariablesResiduals <- c(rep(1,23), -->
<!--                         rep(2,23), -->
<!--                         rep(3,23), -->
<!--                         rep(4,23), -->
<!--                         rep(5,23), -->
<!--                         rep(6,23), -->
<!--                         rep(7,23), -->
<!--                         rep(8,23), -->
<!--                         rep(9,23) -->
<!--                       ) -->

<!-- ResidualsTable <- data.frame(Residuals = residualsT, Variables = VariablesResiduals) -->

<!-- ResidualsTable$Variables <- as.factor(ResidualsTable$Variables) -->
<!-- dp1 <- ggplot(ResidualsTable, aes(x=Variables, y= Residuals, fill=Variables)) +  -->
<!--   geom_violin(trim=FALSE)+ -->
<!--   geom_boxplot(width=0.1, fill='white')+ -->
<!--   labs(title="",x="# of variables selected", y = "Residuals (mg/kg)") -->
<!-- dp1 + scale_fill_brewer(palette="Greens") + theme_minimal() -->

<!-- ``` -->
<!-- # Significance of models -->

<!-- ```{r} -->
<!-- win.graph() -->

<!-- pValTable <- data.frame(matrix(nrow = 9, nrow = 12)) -->


<!-- summary(listOfModels1[[1]])$coefficients[,4] -->
<!-- win.graph() -->
<!-- par(mfrow = c(3,3)) -->
<!-- for(i in 1:9){ -->
<!--    barplot(summary(listOfModels1[[i]])$coefficients[,4], -->

<!--           horiz = T, -->
<!--           names.arg = c('intercept', colnames(leavesSiSpectra[,gen$bestsets[i,]]))) -->
<!--   abline(v = 0.05, lty =2) -->

<!-- } -->

<!-- ``` -->


<!-- ```{r} -->
<!-- summary(mols) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- predictions8Var <- predict(mols,  newdata = as.data.frame(leavesSiSpectra[,gen$bestsets[4,]])) -->
<!--  n -->
<!-- predY8var <- predictions8Var -->

<!-- table8bar <- data.frame(I( predX8Var),I(predY8var)) -->

<!-- lm.C <- lm(predX8Var~predY8var) -->

<!-- plot(predX8Var, -->
<!-- 	 predY8var, -->
<!-- 	 xlab="Actual Si (ppm)" , -->
<!--  	 ylab="Predicted Si (ppm)", -->
<!--  	 pch=17, -->
<!--  	 cex=1.2, -->
<!--  	 col="darkorchid4", -->
<!--  	 cex.lab=1 -->
<!--  	 ) -->
<!-- abline(a=0  , b=1, col=1, lty=1, lwd=2) -->
<!-- # legend("topleft", recta.restado, pch=pch ,col=colfin, cex=1) -->

<!-- ``` -->
<!-- ## cross validation for MOLS and selected variables -->




<!-- ```{r} -->
<!-- library(tidyverse) -->
<!-- library(caret) -->

<!-- # First we create a list of tables with the best subsets selected by the genetic algorithm -->

<!-- listOfTables <- vector('list', nrow(gen$bestsets)) -->

<!-- listOfModels <- vector('list', nrow(gen$bestsets)) -->

<!-- listOfRMSEP <- vector('list', nrow(gen$bestsets)) -->

<!-- system.time( -->
<!-- for(i in 1:nrow(gen$bestsets)){ -->

<!--  listOfTables[[i]] <- cbind(Si  = metadata.leaves.Si$Si, as.data.frame(leavesSiSpectra[,gen$bestsets[i,]])) -->


<!--  # setting seed to generate a -->
<!-- # reproducible random sampling -->
<!-- set.seed(125) -->

<!-- # defining training control as -->
<!-- # repeated cross-validation and -->
<!-- # value of K is 10 and repetition is 100 times -->

<!-- train_control <- trainControl(method = "repeatedcv", -->
<!--                             number = 10, repeats = 100) -->

<!-- # training the model by assigning sales column -->
<!-- # as target variable and rest other column -->
<!-- # as independent variable -->

<!-- listOfModels[[i]] <- train(Si ~.,  -->
<!--                        data = listOfTables[[i]], -->
<!--                        method = "lm", -->
<!--                       trControl = train_control) -->


<!-- listOfRMSEP[[i]] <- listOfModels[[i]]$resample$RMSE -->

<!-- } -->

<!-- ) -->

<!-- RMSEP <- c(listOfRMSEP[[1]],listOfRMSEP[[2]],listOfRMSEP[[3]],listOfRMSEP[[4]],listOfRMSEP[[5]],listOfRMSEP[[6]],listOfRMSEP[[7]],listOfRMSEP[[8]],listOfRMSEP[[9]]) -->



<!-- RMSEPTable <- data.frame(RMSEP = RMSEP, variables = c(rep(4,1000),rep(5,1000),rep(6,1000),rep(7,1000),rep(8,1000),rep(9,1000),rep(10,1000),rep(11,1000),rep(12,1000))) -->

<!-- RMSEPTable$variables <- as.factor(RMSEPTable$variables) -->


<!-- # # R program to implement -->
<!-- # # repeated K-fold cross-validation -->
<!-- #   -->
<!-- # # setting seed to generate a -->
<!-- # # reproducible random sampling -->
<!-- # set.seed(125) -->
<!-- #   -->
<!-- # # defining training control as -->
<!-- # # repeated cross-validation and -->
<!-- # # value of K is 10 and repetation is 3 times -->
<!-- # train_control <- trainControl(method = "repeatedcv", -->
<!-- #                             number = 10, repeats = 3) -->
<!-- #   -->
<!-- # # training the model by assigning sales column -->
<!-- # # as target variable and rest other column -->
<!-- # # as independent variable -->
<!-- # model <- train(Si ~., data = marketing, -->
<!-- #                method = "lm", -->
<!-- #                trControl = train_control) -->
<!-- #   -->
<!-- # # printing model performance metrics -->
<!-- # # along with other details -->
<!-- # print(model) -->
<!-- ``` -->



<!-- ```{r cross validation graph} -->


<!-- dp <- ggplot(RMSEPTable, aes(x=variables, y=RMSEP, fill=variables)) +  -->
<!--   geom_violin(trim=FALSE)+ -->
<!--   geom_boxplot(width=0.1, fill='white')+ -->
<!--   labs(title="CVRMSE vs # of variables ",x="# of variables selected", y = "RMSE (n = 1000)") -->
<!-- dp + scale_fill_brewer(palette="Blues") + theme_minimal() -->



<!-- ``` -->

<!-- # NIST Apple Leaves Reference material infrared spectra -->




<!-- ## Importing data -->

<!-- ```{r} -->
<!-- namesNIST <- list.files(path = "./AppleLeaves",pattern = '.CSV') -->
<!-- spectra.listNIST <- lapply(paste0('./AppleLeaves/',namesNIST), read.csv, header = F) -->
<!-- wavenumbersNIST <- unlist(spectra.listNIST[[1]][1]) -->
<!-- spectra.list2NIST <- lapply(spectra.listNIST, '[', 2) -->
<!-- spectra.dfNIST <- as.data.frame(t(as.data.frame(spectra.list2NIST))) -->
<!-- rownames(spectra.dfNIST) <- namesNIST -->
<!-- colnames(spectra.dfNIST) <- wavenumbersNIST -->



<!-- ``` -->


<!-- ## plotting initial data for NIST samples -->

<!-- ```{r} -->
<!-- for(i in  1:length(rownames(spectra.dfNIST))){ -->

<!--   plot(wavenumbersNIST, -->
<!--     spectra.dfNIST[i,], -->
<!--     axes = F, -->
<!--     xlab = '',  -->
<!--     ylab = '', -->
<!--     xlim = c(4000, 400), -->
<!--     ylim= c(0,0.2), -->
<!--     type = 'l', -->
<!--     col ='black' -->

<!--   ) -->
<!--   par(new = T) -->
<!-- } -->

<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = 'raw spectra full range', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab ='absorbance (a.u.)') -->
<!-- ``` -->

<!-- ## range selection for NIST samples -->

<!-- ```{r} -->
<!-- colnames(spectra.df)[c(1,676)] -->
<!-- ``` -->
<!-- ```{r} -->
<!-- range1NIST <- spectra.dfNIST[,c(1:676)] -->
<!-- wavenumbers1NIST <- wavenumbersNIST[c(1:676)] -->
<!-- for(i in  1:length(rownames(range1NIST))){ -->

<!--   plot(wavenumbers1NIST, -->
<!--     range1NIST[i,], -->
<!--     axes = F, -->
<!--     xlab = '',  -->
<!--     ylab = '', -->
<!--     xlim = c(1700, 400), -->
<!--     ylim= c(0,0.1), -->
<!--     type = 'l', -->
<!--     col ="black" -->

<!--   ) -->
<!--   par(new = T) -->
<!-- } -->

<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = 'raw spectra - ROI', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab ='absorbance (a.u.)') -->
<!-- ``` -->

<!-- # baseline correction for NIST samples -->


<!-- ```{r} -->
<!-- library(hyperSpec) -->


<!-- spcNIST <- new('hyperSpec', -->
<!--            spc= range1NIST,  -->
<!--            wavelength = wavenumbers1NIST) -->

<!-- bendNIST <- 0.1 * wl.eval(spcNIST, -->
<!--                       function (x) x^6+x^5+x^4+x^3+x^2, -->
<!--                       normalize.wl = normalize01) -->

<!-- blNIST <- spc.rubberband(spcNIST+bendNIST, noise = 1e-4, df = 20)-bendNIST -->
<!-- sumNIST <- spcNIST+bendNIST -->
<!-- spc3NIST <- spcNIST - blNIST -->

<!-- plot(spcNIST, wl.reverse = TRUE) -->
<!-- plot(blNIST, add=TRUE, col=2,wl.reverse = TRUE) -->
<!-- plot(sumNIST,wl.reverse = TRUE) -->
<!-- plot(bendNIST, add=TRUE, col=2,wl.reverse = TRUE) -->
<!-- plot(spc3NIST,wl.reverse = TRUE) -->

<!-- corrected1NIST  <- as.data.frame(spc3NIST[1:5]) -->
<!-- correctedNIST <- as.data.frame(corrected1NIST[,1]) -->
<!-- correctedNIST <- correctedNIST + (min(correctedNIST)*-1) # shifting upwards to prevent negative values -->
<!-- ``` -->

<!-- # prediction of Si content using MOLS with variables selected by genetic algorithms -->

<!-- ```{r} -->

<!-- listOfNISTPredictions <- vector('list', length = length(listOfModels)) -->
<!-- for(i in 1:length(listOfModels)){ -->

<!--  listOfNISTPredictions[[i]] <- predict(listOfModels[[i]], newdata = as.data.frame(correctedNIST[,gen$bestsets[i,]]))  -->

<!-- } -->
<!-- ``` -->

<!-- In the list called `listOfNISTPredictions` we have the prediction fo Si content for each NIST sample. If whe reference value is 400 mg/Kg. we can calculate a relative error: -->

<!-- ```{r} -->

<!-- listOfNISTErrors <- vector('list', length = length(listOfModels)) -->
<!-- for(i in 1:length(listOfNISTPredictions)) -->
<!-- listOfNISTErrors[[i]] <- (abs(listOfNISTPredictions[[i]]-400)/400)*100 -->
<!-- ``` -->


<!-- ## PLS with new variables -->

<!-- ```{r} -->


<!-- library(pls) -->
<!-- SiPLSgen <- plsr(SiTable$Si~ leavesSiSpectra[,gen$bestsets[3,]],  -->
<!--               data = SiTable, -->
<!--               validation = 'LOO') -->


<!-- ``` -->

<!-- ```{r} -->
<!-- plot(RMSEP(SiPLSgen),type="b",legendpos="topright") -->
<!-- ``` -->


<!-- ```{r} -->
<!-- plot(SiPLS,ncomp=4,line=TRUE) -->
<!-- ``` -->









<!-- # Predicting silicon in other tissues -->
<!-- ## wheat straw -->

<!-- ### Sample selection -->

<!-- First, we ask R where can we find straw samples in `metadata` -->

<!-- ```{r} -->
<!-- straw.index <- which(grepl(paste0('(?=.*','S',')'),metadata$class,perl = T)) -->
<!-- straw.index -->
<!-- ``` -->

<!-- Now that we know where these samples are, we can separate these samples in a new  data set: -->

<!-- ```{r} -->
<!-- metadata.straw <- metadata[straw.index,] -->
<!-- head(metadata.straw) -->
<!-- ``` -->

<!-- ### preparing for quantification - deleting samples that have `NA` for spectra index -->

<!-- Here we will ask for which samples have no spectra, or silicon content. -->

<!-- ```{r} -->
<!-- which(is.na(metadata.straw$Si)) -->
<!-- which(is.na(metadata.straw$spectra)) -->
<!-- ``` -->
<!-- In the row `11`, we have a `NA` for spectra *and* for silicon content. for samples: `19`, `20`, `21` and `22` Let us inspect which samples are in these rows: -->

<!-- ```{r} -->
<!-- metadata.straw$sample[c(11,19,20,21,22)] -->
<!-- ``` -->

<!-- In order to not lose information for other analyses, we can create a new object called `metadata.strawSi` without these samples: -->


<!-- ```{r} -->
<!-- metadataStrawSi <- metadata.straw[-c(11,19,20,21,22),] -->
<!-- ``` -->

<!-- We can create a subset table with corrected mean spectra for straw samples: -->

<!-- ```{r} -->
<!-- StrawSiSpectra <- corrected[metadataStrawSi$spectra.index,] -->

<!-- for (i in 1:length(rownames(StrawSiSpectra))){ -->

<!--   plot(as.numeric(colnames(StrawSiSpectra)),  -->
<!--      StrawSiSpectra[i,], -->
<!--      xlab = '', -->
<!--      ylab = '', -->
<!--      axes = F, -->
<!--      type = 'l', -->
<!--      xlim = c(1700,400), -->
<!--      ylim = c(0,0.06)) -->
<!--   par(new = T) -->
<!-- } -->
<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = '', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab = 'Absorbance (a.u.)') -->

<!-- ``` -->


<!-- ### quantification using each of the models built with leaves data -->

<!-- pendiente, hacer matriz de correlacion con los espectros de hojas que se usaron para construir los modelos, para ver lignina - silica -->

<!-- ```{r} -->
<!-- listOfStrawPredictions <-  vector('list', length = length(listOfModels)) -->

<!-- for(i in 1:length(listOfModels)){ -->

<!--  listOfStrawPredictions[[i]] <- predict(listOfModels[[i]], newdata = as.data.frame(StrawSiSpectra[,gen$bestsets[i,]]))  -->

<!-- } -->
<!-- ``` -->

<!-- In the list called `listOfStrawPredictions` we have the prediction for Si content for each straw sample. We can calculate the difference between each of these values and the values present at `metadataStrawSi$Si`, for each model: -->

<!-- ```{r} -->
<!-- listOfStrawErrors <- vector('list', length = length(listOfModels)) -->
<!-- for(i in 1:length(listOfStrawErrors)){ -->

<!-- listOfStrawErrors[[i]] <- (abs(listOfStrawPredictions[[i]]-metadataStrawSi$Si)/metadataStrawSi$Si)*100 -->

<!-- } -->
<!-- ``` -->

<!-- we can assess the distribution of errors as follows: -->

<!-- ```{r} -->
<!-- # First, we have a list. we have to convert this list to a data.frame. with one column of errors and one column of model identifier: -->

<!-- vectorOfStrawErrors <- unlist(listOfStrawErrors) -->


<!-- StrawErrorsdf <- data.frame(error = vectorOfStrawErrors, model= as.factor(rep(4:12,each =20))) -->

<!-- dp <- ggplot(StrawErrorsdf, aes(x= model, y=error, fill=model)) +  -->
<!--   geom_violin(trim=FALSE)+ -->
<!--   geom_boxplot(width=0.1, fill='white')+ -->
<!--   labs(title="error of prediction for straw samples",x="# of variables selected", y = "relative error (n=20)") -->
<!-- dp + scale_fill_brewer(palette="Blues") + theme_minimal() + geom_hline(yintercept=100)  -->

<!-- ``` -->




<!-- ## wheat roots -->

<!-- ### Sample selection -->

<!-- First, we ask R where can we find roots samples in `metadata` -->

<!-- ```{r} -->
<!-- Roots.index <- which(grepl(paste0('(?=.*','R',')'),metadata$class,perl = T)) -->
<!-- Roots.index -->
<!-- ``` -->

<!-- Now that we know where these samples are, we can separate these samples in a new  data set: -->

<!-- ```{r} -->
<!-- metadata.Roots <- metadata[Roots.index,] -->
<!-- head(metadata.Roots) -->
<!-- ``` -->

<!-- ### preparing for quantification - deleting samples that have `NA` for spectra index -->

<!-- Here we will ask for which samples have no spectra, or silicon content. -->

<!-- ```{r} -->
<!-- which(is.na(metadata.Roots$Si)) -->
<!-- which(is.na(metadata.Roots$spectra)) -->
<!-- ``` -->
<!-- In the row `11`, we have a `NA` for spectra *and* for silicon content. for samples: `19`, `20`, `21` and `22` Let us inspect which samples are in these rows: -->

<!-- ```{r} -->
<!-- metadata.Roots$sample[c(6,8)] -->
<!-- ``` -->

<!-- In order to not lose information for other analyses, we can create a new object called `metadataRootsSi` without these samples: -->


<!-- ```{r} -->
<!-- metadataRootsSi <- metadata.Roots[-c(6,8),] -->
<!-- ``` -->

<!-- We can create a subset table with corrected mean spectra for Roots samples: -->

<!-- ```{r} -->
<!-- RootsSiSpectra <- corrected[metadataRootsSi$spectra.index,] -->

<!-- for (i in 1:length(rownames(RootsSiSpectra))){ -->

<!--   plot(as.numeric(colnames(RootsSiSpectra)),  -->
<!--      RootsSiSpectra[i,], -->
<!--      xlab = '', -->
<!--      ylab = '', -->
<!--      axes = F, -->
<!--      type = 'l', -->
<!--      xlim = c(1700,400), -->
<!--      ylim = c(0,0.06)) -->
<!--   par(new = T) -->
<!-- } -->
<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = '', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab = 'Absorbance (a.u.)') -->

<!-- ``` -->


<!-- ### quantification using each of the models built with leaves data -->

<!-- ```{r} -->
<!-- listOfRootsPredictions <-  vector('list', length = length(listOfModels)) -->

<!-- for(i in 1:length(listOfModels)){ -->

<!--  listOfRootsPredictions[[i]] <- predict(listOfModels[[i]], newdata = as.data.frame(RootsSiSpectra))  -->

<!-- } -->
<!-- ``` -->

<!-- In the list called `listOfRootsPredictions` we have the prediction for Si content for each Roots sample. We can calculate the difference between each of these values and the values present at `metadataRootsSi$Si`, for each model: -->

<!-- ```{r} -->
<!-- listOfRootsErrors <- vector('list', length = length(listOfModels)) -->
<!-- for(i in 1:length(listOfRootsErrors)){ -->

<!-- listOfRootsErrors[[i]] <- (abs(listOfRootsPredictions[[i]]-metadataRootsSi$Si)/metadataRootsSi$Si)*100 -->

<!-- } -->
<!-- ``` -->

<!-- we can assess the distribution of errors as follows: -->

<!-- ```{r} -->
<!-- # First, we have a list. we have to convert this list to a data.frame. with one column of errors and one column of model identifier: -->

<!-- vectorOfRootsErrors <- unlist(listOfRootsErrors) -->


<!-- RootsErrorsdf <- data.frame(error = vectorOfRootsErrors, model= as.factor(rep(4:12,each = 16))) -->

<!-- dp <- ggplot(RootsErrorsdf, aes(x= model, y=error, fill=model)) +  -->
<!--   geom_violin(trim=FALSE)+ -->
<!--   geom_boxplot(width=0.1, fill='white')+ -->
<!--   labs(title="error of prediction for Roots samples",x="# of variables selected", y = "relative error (n=20)") -->
<!-- dp + scale_fill_brewer(palette="Blues") + theme_minimal() + geom_hline(yintercept=100)  -->

<!-- ``` -->




<!-- # zero with ludox silica -->

<!-- ## Importing data -->

<!-- ```{r} -->
<!-- namesludox <- list.files(path = "./AppleLeaves",pattern = '.CSV') -->
<!-- spectra.listludox <- lapply(paste0('./AppleLeaves/',namesludox), read.csv, header = F) -->
<!-- wavenumbersludox <- unlist(spectra.listludox[[1]][1]) -->
<!-- spectra.list2ludox <- lapply(spectra.listludox, '[', 2) -->
<!-- spectra.dfludox <- as.data.frame(t(as.data.frame(spectra.list2ludox))) -->
<!-- rownames(spectra.dfludox) <- namesludox -->
<!-- colnames(spectra.dfludox) <- wavenumbersludox -->
<!-- ``` -->

<!-- ## plotting initial data for ludox samples -->

<!-- ```{r} -->
<!-- for(i in  1:length(rownames(spectra.dfludox))){ -->

<!--   plot(wavenumbersludox, -->
<!--     spectra.dfludox[i,], -->
<!--     axes = F, -->
<!--     xlab = '',  -->
<!--     ylab = '', -->
<!--     xlim = c(4000, 400), -->
<!--     ylim= c(0,0.2), -->
<!--     type = 'l', -->
<!--     col ='black' -->

<!--   ) -->
<!--   par(new = T) -->
<!-- } -->

<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = 'raw spectra full range', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab ='absorbance (a.u.)') -->
<!-- ``` -->


<!-- ## range selection for ludox samples -->

<!-- ```{r} -->
<!-- colnames(spectra.df)[c(1,676)] -->
<!-- ``` -->
<!-- ```{r} -->
<!-- range1ludox <- spectra.dfludox[,c(1:676)] -->
<!-- wavenumbers1ludox <- wavenumbersludox[c(1:676)] -->
<!-- for(i in  1:length(rownames(range1ludox))){ -->

<!--   plot(wavenumbers1ludox, -->
<!--     range1ludox[i,], -->
<!--     axes = F, -->
<!--     xlab = '',  -->
<!--     ylab = '', -->
<!--     xlim = c(1700, 400), -->
<!--     ylim= c(0,0.1), -->
<!--     type = 'l', -->
<!--     col ="black" -->

<!--   ) -->
<!--   par(new = T) -->
<!-- } -->

<!-- box() -->
<!-- axis(1) -->
<!-- axis(2) -->
<!-- title(main = 'raw spectra - ROI', -->
<!--       xlab = expression(paste('Wave number (cm'^'-1',')')), -->
<!--       ylab ='absorbance (a.u.)') -->
<!-- ``` -->



<!-- # baseline correction for ludox samples -->


<!-- ```{r} -->
<!-- library(hyperSpec) -->


<!-- spcludox <- new('hyperSpec', -->
<!--            spc= range1ludox,  -->
<!--            wavelength = wavenumbers1ludox) -->

<!-- bendludox <- 0.1 * wl.eval(spcludox, -->
<!--                       function (x) x^6+x^5+x^4+x^3+x^2, -->
<!--                       normalize.wl = normalize01) -->

<!-- blludox <- spc.rubberband(spcludox+bendludox, noise = 1e-4, df = 20)-bendludox -->
<!-- sumludox <- spcludox+bendludox -->
<!-- spc3ludox <- spcludox - blludox -->

<!-- plot(spcludox, wl.reverse = TRUE) -->
<!-- plot(blludox, add=TRUE, col=2,wl.reverse = TRUE) -->
<!-- plot(sumludox,wl.reverse = TRUE) -->
<!-- plot(bendludox, add=TRUE, col=2,wl.reverse = TRUE) -->
<!-- plot(spc3ludox,wl.reverse = TRUE) -->

<!-- corrected1ludox  <- as.data.frame(spc3ludox[1:5]) -->
<!-- correctedludox <- as.data.frame(corrected1ludox[,1]) -->
<!-- correctedludox <- correctedludox + (min(correctedludox)*-1) # shifting upwards to prevent negative values -->
<!-- ``` -->



<!-- # Classification -->

<!-- In order to use classification algorithms, we can create a new dataset without missing values in `metadata$spectra`, `metadata$class`, and `metadata$Si`  -->

<!-- ```{r} -->
<!-- which(is.na(metadata$spectra)) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- which(is.na(metadata$class)) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- which(is.na(metadata$Si)) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- unique( -->
<!--           c( which(is.na(metadata$spectra)), -->
<!--              which(is.na(metadata$class)), -->
<!--              which(is.na(metadata$Si))) -->
<!--        ) -->

<!-- missing <- unique( -->
<!--           c( which(is.na(metadata$spectra)), -->
<!--              which(is.na(metadata$class)), -->
<!--              which(is.na(metadata$Si))) -->
<!--        ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- metadata.class <- metadata[-missing,] -->
<!-- ``` -->

<!-- ## Hierarchical clustering and k-means -->


